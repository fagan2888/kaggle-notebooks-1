{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F2RjUhNsqY4L"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "data_path = \"human_text.txt\"\n",
    "data_path2 = \"robot_text.txt\"\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')\n",
    "with open(data_path2, 'r', encoding='utf-8') as f:\n",
    "  lines2 = f.read().split('\\n')\n",
    "lines = [re.sub(r\"\\[\\w+\\]\",'hi',line) for line in lines]\n",
    "lines = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines]\n",
    "lines2 = [re.sub(r\"\\[\\w+\\]\",'',line) for line in lines2]\n",
    "lines2 = [\" \".join(re.findall(r\"\\w+\",line)) for line in lines2]\n",
    "# Grouping lines by response pair\n",
    "pairs = list(zip(lines,lines2))\n",
    "#random.shuffle(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "bw7iFyTEFriu",
    "outputId": "d10fd3a9-023e-4850-ef35-2dbac08098a0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "for line in pairs[:400]:\n",
    "  input_doc, target_doc = line[0], line[1]\n",
    "  # Appending each input sentence to input_docs\n",
    "  input_docs.append(input_doc)\n",
    "  # Splitting words from punctuation  \n",
    "  target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "  # Redefine target_doc below and append it to target_docs\n",
    "  target_doc = '<START> ' + target_doc + ' <END>'\n",
    "  target_docs.append(target_doc)\n",
    "  \n",
    "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
    "  for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "    if token not in input_tokens:\n",
    "      input_tokens.add(token)\n",
    "  for token in target_doc.split():\n",
    "    if token not in target_tokens:\n",
    "      target_tokens.add(token)\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n",
    "\n",
    "\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        if timestep > 0:\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "NPRH_kUNKaHE",
    "outputId": "4fb20057-4685-4332-9dff-45b9de2fc7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', 'hi there how are you'), ('oh thanks i m fine this is an evening in my timezone', 'here is afternoon'), ('how do you feel today tell me something about yourself', 'my name is rdany but you can call me dany the r means robot i hope we can be virtual friends'), ('how many virtual friends have you got', 'i have many but not enough to fully understand humans beings'), ('is that forbidden for you to tell the exact number', 'i ve talked with 143 users counting 7294 lines of text')]\n",
      "['hi', 'oh thanks i m fine this is an evening in my timezone', 'how do you feel today tell me something about yourself', 'how many virtual friends have you got', 'is that forbidden for you to tell the exact number']\n"
     ]
    }
   ],
   "source": [
    "print(pairs[:5])\n",
    "print(input_docs[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QZZcikCkFulO",
    "outputId": "d720c441-8b2b-4d6d-87c9-db0e3afe54eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 1.2238 - accuracy: 0.0222 - val_loss: 1.3509 - val_accuracy: 0.0200\n",
      "Epoch 2/600\n",
      "32/32 [==============================] - 25s 789ms/step - loss: 1.1383 - accuracy: 0.0241 - val_loss: 1.3870 - val_accuracy: 0.0200\n",
      "Epoch 3/600\n",
      "32/32 [==============================] - 25s 776ms/step - loss: 1.1406 - accuracy: 0.0236 - val_loss: 1.4530 - val_accuracy: 0.0200\n",
      "Epoch 4/600\n",
      "32/32 [==============================] - 25s 769ms/step - loss: 1.1094 - accuracy: 0.0244 - val_loss: 1.4616 - val_accuracy: 0.0207\n",
      "Epoch 5/600\n",
      "32/32 [==============================] - 26s 797ms/step - loss: 1.0973 - accuracy: 0.0241 - val_loss: 1.4811 - val_accuracy: 0.0203\n",
      "Epoch 6/600\n",
      "32/32 [==============================] - 24s 759ms/step - loss: 1.0903 - accuracy: 0.0246 - val_loss: 1.4791 - val_accuracy: 0.0205\n",
      "Epoch 7/600\n",
      "32/32 [==============================] - 26s 801ms/step - loss: 1.0753 - accuracy: 0.0239 - val_loss: 1.4773 - val_accuracy: 0.0210\n",
      "Epoch 8/600\n",
      "32/32 [==============================] - 24s 754ms/step - loss: 1.0699 - accuracy: 0.0249 - val_loss: 1.5110 - val_accuracy: 0.0210\n",
      "Epoch 9/600\n",
      "32/32 [==============================] - 24s 754ms/step - loss: 1.0594 - accuracy: 0.0244 - val_loss: 1.5246 - val_accuracy: 0.0210\n",
      "Epoch 10/600\n",
      "32/32 [==============================] - 24s 742ms/step - loss: 1.0541 - accuracy: 0.0248 - val_loss: 1.5364 - val_accuracy: 0.0195\n",
      "Epoch 11/600\n",
      "32/32 [==============================] - 25s 767ms/step - loss: 1.0420 - accuracy: 0.0247 - val_loss: 1.5601 - val_accuracy: 0.0213\n",
      "Epoch 12/600\n",
      "32/32 [==============================] - 24s 759ms/step - loss: 1.0320 - accuracy: 0.0256 - val_loss: 1.5509 - val_accuracy: 0.0217\n",
      "Epoch 13/600\n",
      "32/32 [==============================] - 24s 754ms/step - loss: 1.0238 - accuracy: 0.0254 - val_loss: 1.5450 - val_accuracy: 0.0210\n",
      "Epoch 14/600\n",
      "32/32 [==============================] - 25s 775ms/step - loss: 1.0143 - accuracy: 0.0262 - val_loss: 1.5811 - val_accuracy: 0.0223\n",
      "Epoch 15/600\n",
      "32/32 [==============================] - 24s 753ms/step - loss: 1.0019 - accuracy: 0.0276 - val_loss: 1.5832 - val_accuracy: 0.0213\n",
      "Epoch 16/600\n",
      "32/32 [==============================] - 24s 752ms/step - loss: 0.9924 - accuracy: 0.0283 - val_loss: 1.5922 - val_accuracy: 0.0220\n",
      "Epoch 17/600\n",
      "32/32 [==============================] - 25s 785ms/step - loss: 0.9790 - accuracy: 0.0289 - val_loss: 1.5863 - val_accuracy: 0.0223\n",
      "Epoch 18/600\n",
      "32/32 [==============================] - 24s 761ms/step - loss: 0.9670 - accuracy: 0.0299 - val_loss: 1.5773 - val_accuracy: 0.0213\n",
      "Epoch 19/600\n",
      "32/32 [==============================] - 24s 758ms/step - loss: 0.9548 - accuracy: 0.0304 - val_loss: 1.5622 - val_accuracy: 0.0240\n",
      "Epoch 20/600\n",
      "32/32 [==============================] - 24s 759ms/step - loss: 0.9404 - accuracy: 0.0322 - val_loss: 1.5947 - val_accuracy: 0.0225\n",
      "Epoch 21/600\n",
      "32/32 [==============================] - 25s 774ms/step - loss: 0.9239 - accuracy: 0.0341 - val_loss: 1.6043 - val_accuracy: 0.0223\n",
      "Epoch 22/600\n",
      "32/32 [==============================] - 24s 749ms/step - loss: 0.9105 - accuracy: 0.0339 - val_loss: 1.5970 - val_accuracy: 0.0233\n",
      "Epoch 23/600\n",
      "32/32 [==============================] - 24s 756ms/step - loss: 0.8917 - accuracy: 0.0365 - val_loss: 1.5931 - val_accuracy: 0.0227\n",
      "Epoch 24/600\n",
      "32/32 [==============================] - 24s 754ms/step - loss: 0.8833 - accuracy: 0.0375 - val_loss: 1.5962 - val_accuracy: 0.0235\n",
      "Epoch 25/600\n",
      "32/32 [==============================] - 24s 750ms/step - loss: 0.8603 - accuracy: 0.0388 - val_loss: 1.5797 - val_accuracy: 0.0227\n",
      "Epoch 26/600\n",
      "32/32 [==============================] - 24s 751ms/step - loss: 0.8526 - accuracy: 0.0399 - val_loss: 1.6225 - val_accuracy: 0.0220\n",
      "Epoch 27/600\n",
      "32/32 [==============================] - 24s 753ms/step - loss: 0.8411 - accuracy: 0.0413 - val_loss: 1.6013 - val_accuracy: 0.0217\n",
      "Epoch 28/600\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.8138 - accuracy: 0.0436 - val_loss: 1.5976 - val_accuracy: 0.0223\n",
      "Epoch 29/600\n",
      "32/32 [==============================] - 25s 768ms/step - loss: 0.7927 - accuracy: 0.0461 - val_loss: 1.6023 - val_accuracy: 0.0198\n",
      "Epoch 30/600\n",
      "32/32 [==============================] - 25s 769ms/step - loss: 0.7780 - accuracy: 0.0483 - val_loss: 1.6070 - val_accuracy: 0.0245\n",
      "Epoch 31/600\n",
      "32/32 [==============================] - 29s 898ms/step - loss: 0.7609 - accuracy: 0.0504 - val_loss: 1.6036 - val_accuracy: 0.0240\n",
      "Epoch 32/600\n",
      "32/32 [==============================] - 28s 888ms/step - loss: 0.7598 - accuracy: 0.0507 - val_loss: 1.6039 - val_accuracy: 0.0250\n",
      "Epoch 33/600\n",
      "32/32 [==============================] - 30s 934ms/step - loss: 0.7280 - accuracy: 0.0549 - val_loss: 1.6264 - val_accuracy: 0.0245\n",
      "Epoch 34/600\n",
      "32/32 [==============================] - 25s 795ms/step - loss: 0.7023 - accuracy: 0.0581 - val_loss: 1.6301 - val_accuracy: 0.0220\n",
      "Epoch 35/600\n",
      "32/32 [==============================] - 25s 774ms/step - loss: 0.6835 - accuracy: 0.0613 - val_loss: 1.6304 - val_accuracy: 0.0250\n",
      "Epoch 36/600\n",
      "32/32 [==============================] - 26s 802ms/step - loss: 0.6659 - accuracy: 0.0641 - val_loss: 1.6349 - val_accuracy: 0.0230\n",
      "Epoch 37/600\n",
      "32/32 [==============================] - 25s 795ms/step - loss: 0.6475 - accuracy: 0.0679 - val_loss: 1.6225 - val_accuracy: 0.0223\n",
      "Epoch 38/600\n",
      "32/32 [==============================] - 24s 745ms/step - loss: 0.6293 - accuracy: 0.0720 - val_loss: 1.6469 - val_accuracy: 0.0227\n",
      "Epoch 39/600\n",
      "32/32 [==============================] - 25s 772ms/step - loss: 0.6077 - accuracy: 0.0756 - val_loss: 1.6584 - val_accuracy: 0.0235\n",
      "Epoch 40/600\n",
      "32/32 [==============================] - 24s 760ms/step - loss: 0.6118 - accuracy: 0.0766 - val_loss: 1.6559 - val_accuracy: 0.0240\n",
      "Epoch 41/600\n",
      "32/32 [==============================] - 26s 806ms/step - loss: 0.6009 - accuracy: 0.0793 - val_loss: 1.6547 - val_accuracy: 0.0247\n",
      "Epoch 42/600\n",
      "32/32 [==============================] - 25s 766ms/step - loss: 0.5715 - accuracy: 0.0851 - val_loss: 1.6439 - val_accuracy: 0.0225\n",
      "Epoch 43/600\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.5580 - accuracy: 0.0893 - val_loss: 1.6758 - val_accuracy: 0.0253\n",
      "Epoch 44/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.5339 - accuracy: 0.0956 - val_loss: 1.6671 - val_accuracy: 0.0217\n",
      "Epoch 45/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.5070 - accuracy: 0.1015 - val_loss: 1.6957 - val_accuracy: 0.0217\n",
      "Epoch 46/600\n",
      "32/32 [==============================] - 25s 773ms/step - loss: 0.4955 - accuracy: 0.1046 - val_loss: 1.6948 - val_accuracy: 0.0207\n",
      "Epoch 47/600\n",
      "32/32 [==============================] - 24s 761ms/step - loss: 0.4786 - accuracy: 0.1087 - val_loss: 1.7025 - val_accuracy: 0.0230\n",
      "Epoch 48/600\n",
      "32/32 [==============================] - 28s 863ms/step - loss: 0.4571 - accuracy: 0.1128 - val_loss: 1.6822 - val_accuracy: 0.0233\n",
      "Epoch 49/600\n",
      "32/32 [==============================] - 24s 764ms/step - loss: 0.4398 - accuracy: 0.1179 - val_loss: 1.6920 - val_accuracy: 0.0230\n",
      "Epoch 50/600\n",
      "32/32 [==============================] - 25s 775ms/step - loss: 0.4242 - accuracy: 0.1222 - val_loss: 1.7073 - val_accuracy: 0.0243\n",
      "Epoch 51/600\n",
      "32/32 [==============================] - 25s 772ms/step - loss: 0.4076 - accuracy: 0.1254 - val_loss: 1.7069 - val_accuracy: 0.0215\n",
      "Epoch 52/600\n",
      "32/32 [==============================] - 26s 799ms/step - loss: 0.3898 - accuracy: 0.1307 - val_loss: 1.7420 - val_accuracy: 0.0203\n",
      "Epoch 53/600\n",
      "32/32 [==============================] - 24s 757ms/step - loss: 0.3768 - accuracy: 0.1356 - val_loss: 1.7514 - val_accuracy: 0.0220\n",
      "Epoch 54/600\n",
      "32/32 [==============================] - 26s 800ms/step - loss: 0.3611 - accuracy: 0.1373 - val_loss: 1.7343 - val_accuracy: 0.0230\n",
      "Epoch 55/600\n",
      "32/32 [==============================] - 24s 764ms/step - loss: 0.3477 - accuracy: 0.1416 - val_loss: 1.7329 - val_accuracy: 0.0190\n",
      "Epoch 56/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.3342 - accuracy: 0.1434 - val_loss: 1.7360 - val_accuracy: 0.0207\n",
      "Epoch 57/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 24s 756ms/step - loss: 0.3232 - accuracy: 0.1468 - val_loss: 1.7420 - val_accuracy: 0.0220\n",
      "Epoch 58/600\n",
      "32/32 [==============================] - 25s 770ms/step - loss: 0.3156 - accuracy: 0.1486 - val_loss: 1.7747 - val_accuracy: 0.0215\n",
      "Epoch 59/600\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.3018 - accuracy: 0.1511 - val_loss: 1.7483 - val_accuracy: 0.0235\n",
      "Epoch 60/600\n",
      "32/32 [==============================] - 24s 765ms/step - loss: 0.2880 - accuracy: 0.1544 - val_loss: 1.7852 - val_accuracy: 0.0225\n",
      "Epoch 61/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.2777 - accuracy: 0.1558 - val_loss: 1.7674 - val_accuracy: 0.0203\n",
      "Epoch 62/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.2701 - accuracy: 0.1577 - val_loss: 1.7727 - val_accuracy: 0.0217\n",
      "Epoch 63/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.2598 - accuracy: 0.1602 - val_loss: 1.7787 - val_accuracy: 0.0233\n",
      "Epoch 64/600\n",
      "32/32 [==============================] - 24s 763ms/step - loss: 0.2521 - accuracy: 0.1606 - val_loss: 1.7892 - val_accuracy: 0.0188\n",
      "Epoch 65/600\n",
      "32/32 [==============================] - 25s 785ms/step - loss: 0.2419 - accuracy: 0.1634 - val_loss: 1.7841 - val_accuracy: 0.0225\n",
      "Epoch 66/600\n",
      "32/32 [==============================] - 25s 775ms/step - loss: 0.2320 - accuracy: 0.1641 - val_loss: 1.8028 - val_accuracy: 0.0190\n",
      "Epoch 67/600\n",
      "32/32 [==============================] - 24s 756ms/step - loss: 0.2255 - accuracy: 0.1653 - val_loss: 1.7857 - val_accuracy: 0.0220\n",
      "Epoch 68/600\n",
      "32/32 [==============================] - 25s 766ms/step - loss: 0.2232 - accuracy: 0.1666 - val_loss: 1.8088 - val_accuracy: 0.0190\n",
      "Epoch 69/600\n",
      "32/32 [==============================] - 25s 780ms/step - loss: 0.2129 - accuracy: 0.1681 - val_loss: 1.8033 - val_accuracy: 0.0217\n",
      "Epoch 70/600\n",
      "32/32 [==============================] - 25s 782ms/step - loss: 0.2068 - accuracy: 0.1690 - val_loss: 1.8205 - val_accuracy: 0.0215\n",
      "Epoch 71/600\n",
      "32/32 [==============================] - 25s 782ms/step - loss: 0.2015 - accuracy: 0.1692 - val_loss: 1.8216 - val_accuracy: 0.0198\n",
      "Epoch 72/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.1932 - accuracy: 0.1704 - val_loss: 1.8163 - val_accuracy: 0.0185\n",
      "Epoch 73/600\n",
      "32/32 [==============================] - 24s 765ms/step - loss: 0.1864 - accuracy: 0.1721 - val_loss: 1.8282 - val_accuracy: 0.0192\n",
      "Epoch 74/600\n",
      "32/32 [==============================] - 24s 758ms/step - loss: 0.1806 - accuracy: 0.1734 - val_loss: 1.8106 - val_accuracy: 0.0213\n",
      "Epoch 75/600\n",
      "32/32 [==============================] - 24s 762ms/step - loss: 0.1765 - accuracy: 0.1737 - val_loss: 1.8326 - val_accuracy: 0.0217\n",
      "Epoch 76/600\n",
      "32/32 [==============================] - 25s 768ms/step - loss: 0.1705 - accuracy: 0.1743 - val_loss: 1.8544 - val_accuracy: 0.0205\n",
      "Epoch 77/600\n",
      "32/32 [==============================] - 29s 904ms/step - loss: 0.1659 - accuracy: 0.1754 - val_loss: 1.8525 - val_accuracy: 0.0190\n",
      "Epoch 78/600\n",
      "32/32 [==============================] - 29s 910ms/step - loss: 0.1617 - accuracy: 0.1758 - val_loss: 1.8555 - val_accuracy: 0.0213\n",
      "Epoch 79/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.1579 - accuracy: 0.1778 - val_loss: 1.8546 - val_accuracy: 0.0203\n",
      "Epoch 80/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.1550 - accuracy: 0.1774 - val_loss: 1.8600 - val_accuracy: 0.0185\n",
      "Epoch 81/600\n",
      "32/32 [==============================] - 24s 750ms/step - loss: 0.1508 - accuracy: 0.1781 - val_loss: 1.8732 - val_accuracy: 0.0200\n",
      "Epoch 82/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.1467 - accuracy: 0.1784 - val_loss: 1.8859 - val_accuracy: 0.0178\n",
      "Epoch 83/600\n",
      "32/32 [==============================] - 28s 883ms/step - loss: 0.1431 - accuracy: 0.1784 - val_loss: 1.8825 - val_accuracy: 0.0185\n",
      "Epoch 84/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.1399 - accuracy: 0.1792 - val_loss: 1.8843 - val_accuracy: 0.0185\n",
      "Epoch 85/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.1394 - accuracy: 0.1799 - val_loss: 1.8724 - val_accuracy: 0.0185\n",
      "Epoch 86/600\n",
      "32/32 [==============================] - 28s 869ms/step - loss: 0.1336 - accuracy: 0.1797 - val_loss: 1.9055 - val_accuracy: 0.0203\n",
      "Epoch 87/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.1300 - accuracy: 0.1804 - val_loss: 1.9064 - val_accuracy: 0.0207\n",
      "Epoch 88/600\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 0.1286 - accuracy: 0.1802 - val_loss: 1.8915 - val_accuracy: 0.0188\n",
      "Epoch 89/600\n",
      "32/32 [==============================] - 26s 806ms/step - loss: 0.1262 - accuracy: 0.1818 - val_loss: 1.9035 - val_accuracy: 0.0180\n",
      "Epoch 90/600\n",
      "32/32 [==============================] - 20s 618ms/step - loss: 0.1258 - accuracy: 0.1810 - val_loss: 1.8876 - val_accuracy: 0.0203\n",
      "Epoch 91/600\n",
      "32/32 [==============================] - 16s 500ms/step - loss: 0.1219 - accuracy: 0.1812 - val_loss: 1.9057 - val_accuracy: 0.0180\n",
      "Epoch 92/600\n",
      "32/32 [==============================] - 28s 865ms/step - loss: 0.1192 - accuracy: 0.1820 - val_loss: 1.9130 - val_accuracy: 0.0185\n",
      "Epoch 93/600\n",
      "32/32 [==============================] - 20s 618ms/step - loss: 0.1182 - accuracy: 0.1827 - val_loss: 1.9320 - val_accuracy: 0.0188\n",
      "Epoch 94/600\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 0.1124 - accuracy: 0.1836 - val_loss: 1.9199 - val_accuracy: 0.0198\n",
      "Epoch 95/600\n",
      "32/32 [==============================] - 19s 584ms/step - loss: 0.1124 - accuracy: 0.1826 - val_loss: 1.9394 - val_accuracy: 0.0198\n",
      "Epoch 96/600\n",
      "32/32 [==============================] - 19s 594ms/step - loss: 0.1120 - accuracy: 0.1825 - val_loss: 1.9349 - val_accuracy: 0.0203\n",
      "Epoch 97/600\n",
      "32/32 [==============================] - 20s 612ms/step - loss: 0.1100 - accuracy: 0.1834 - val_loss: 1.9399 - val_accuracy: 0.0190\n",
      "Epoch 98/600\n",
      "32/32 [==============================] - 19s 584ms/step - loss: 0.1100 - accuracy: 0.1831 - val_loss: 1.9402 - val_accuracy: 0.0200\n",
      "Epoch 99/600\n",
      "32/32 [==============================] - 19s 583ms/step - loss: 0.1067 - accuracy: 0.1838 - val_loss: 1.9389 - val_accuracy: 0.0192\n",
      "Epoch 100/600\n",
      "32/32 [==============================] - 19s 585ms/step - loss: 0.1073 - accuracy: 0.1831 - val_loss: 1.9633 - val_accuracy: 0.0203\n",
      "Epoch 101/600\n",
      "32/32 [==============================] - 19s 579ms/step - loss: 0.1038 - accuracy: 0.1839 - val_loss: 1.9632 - val_accuracy: 0.0190\n",
      "Epoch 102/600\n",
      "32/32 [==============================] - 19s 581ms/step - loss: 0.1045 - accuracy: 0.1838 - val_loss: 1.9502 - val_accuracy: 0.0205\n",
      "Epoch 103/600\n",
      "32/32 [==============================] - 19s 581ms/step - loss: 0.1003 - accuracy: 0.1843 - val_loss: 1.9668 - val_accuracy: 0.0178\n",
      "Epoch 104/600\n",
      "32/32 [==============================] - 19s 579ms/step - loss: 0.0999 - accuracy: 0.1837 - val_loss: 1.9796 - val_accuracy: 0.0203\n",
      "Epoch 105/600\n",
      "32/32 [==============================] - 18s 577ms/step - loss: 0.0996 - accuracy: 0.1841 - val_loss: 1.9887 - val_accuracy: 0.0192\n",
      "Epoch 106/600\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 0.0985 - accuracy: 0.1851 - val_loss: 1.9751 - val_accuracy: 0.0192\n",
      "Epoch 107/600\n",
      "32/32 [==============================] - 18s 578ms/step - loss: 0.0980 - accuracy: 0.1845 - val_loss: 1.9823 - val_accuracy: 0.0172\n",
      "Epoch 108/600\n",
      "32/32 [==============================] - 18s 575ms/step - loss: 0.0974 - accuracy: 0.1844 - val_loss: 1.9936 - val_accuracy: 0.0180\n",
      "Epoch 109/600\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 0.0966 - accuracy: 0.1834 - val_loss: 1.9924 - val_accuracy: 0.0200\n",
      "Epoch 110/600\n",
      "32/32 [==============================] - 17s 544ms/step - loss: 0.0924 - accuracy: 0.1849 - val_loss: 2.0077 - val_accuracy: 0.0168\n",
      "Epoch 111/600\n",
      "32/32 [==============================] - 17s 545ms/step - loss: 0.0941 - accuracy: 0.1847 - val_loss: 2.0018 - val_accuracy: 0.0195\n",
      "Epoch 112/600\n",
      "32/32 [==============================] - 18s 547ms/step - loss: 0.0923 - accuracy: 0.1845 - val_loss: 2.0124 - val_accuracy: 0.0188\n",
      "Epoch 113/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 17s 536ms/step - loss: 0.0926 - accuracy: 0.1849 - val_loss: 2.0031 - val_accuracy: 0.0207\n",
      "Epoch 114/600\n",
      "32/32 [==============================] - 17s 537ms/step - loss: 0.0915 - accuracy: 0.1849 - val_loss: 2.0365 - val_accuracy: 0.0195\n",
      "Epoch 115/600\n",
      "32/32 [==============================] - 17s 540ms/step - loss: 0.0910 - accuracy: 0.1844 - val_loss: 2.0188 - val_accuracy: 0.0182\n",
      "Epoch 116/600\n",
      "32/32 [==============================] - 17s 537ms/step - loss: 0.0926 - accuracy: 0.1846 - val_loss: 2.0185 - val_accuracy: 0.0200\n",
      "Epoch 117/600\n",
      "32/32 [==============================] - 17s 536ms/step - loss: 0.0866 - accuracy: 0.1859 - val_loss: 2.0324 - val_accuracy: 0.0192\n",
      "Epoch 118/600\n",
      "32/32 [==============================] - 17s 537ms/step - loss: 0.0859 - accuracy: 0.1863 - val_loss: 2.0445 - val_accuracy: 0.0198\n",
      "Epoch 119/600\n",
      "32/32 [==============================] - 17s 539ms/step - loss: 0.0846 - accuracy: 0.1854 - val_loss: 2.0357 - val_accuracy: 0.0182\n",
      "Epoch 120/600\n",
      "32/32 [==============================] - 17s 535ms/step - loss: 0.0869 - accuracy: 0.1856 - val_loss: 2.0429 - val_accuracy: 0.0195\n",
      "Epoch 121/600\n",
      "32/32 [==============================] - 17s 540ms/step - loss: 0.0907 - accuracy: 0.1848 - val_loss: 2.0328 - val_accuracy: 0.0192\n",
      "Epoch 122/600\n",
      "32/32 [==============================] - 16s 502ms/step - loss: 0.0846 - accuracy: 0.1862 - val_loss: 2.0370 - val_accuracy: 0.0188\n",
      "Epoch 123/600\n",
      "32/32 [==============================] - 16s 503ms/step - loss: 0.0832 - accuracy: 0.1858 - val_loss: 2.0471 - val_accuracy: 0.0175\n",
      "Epoch 124/600\n",
      "32/32 [==============================] - 16s 502ms/step - loss: 0.0886 - accuracy: 0.1848 - val_loss: 2.0713 - val_accuracy: 0.0203\n",
      "Epoch 125/600\n",
      "32/32 [==============================] - 16s 500ms/step - loss: 0.0869 - accuracy: 0.1851 - val_loss: 2.0619 - val_accuracy: 0.0195\n",
      "Epoch 126/600\n",
      "32/32 [==============================] - 16s 504ms/step - loss: 0.0801 - accuracy: 0.1863 - val_loss: 2.0701 - val_accuracy: 0.0195\n",
      "Epoch 127/600\n",
      "32/32 [==============================] - 163s 5s/step - loss: 0.0798 - accuracy: 0.1859 - val_loss: 2.0515 - val_accuracy: 0.0190\n",
      "Epoch 128/600\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.1254 - accuracy: 0.1799 - val_loss: 1.9824 - val_accuracy: 0.0185\n",
      "Epoch 129/600\n",
      "32/32 [==============================] - 24s 748ms/step - loss: 0.1178 - accuracy: 0.1803 - val_loss: 2.0397 - val_accuracy: 0.0178\n",
      "Epoch 130/600\n",
      "32/32 [==============================] - 22s 674ms/step - loss: 0.0825 - accuracy: 0.1868 - val_loss: 2.0601 - val_accuracy: 0.0190\n",
      "Epoch 131/600\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 0.0764 - accuracy: 0.1875 - val_loss: 2.0842 - val_accuracy: 0.0195\n",
      "Epoch 132/600\n",
      "32/32 [==============================] - 19s 606ms/step - loss: 0.0802 - accuracy: 0.1857 - val_loss: 2.0774 - val_accuracy: 0.0178\n",
      "Epoch 133/600\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 0.0776 - accuracy: 0.1866 - val_loss: 2.0944 - val_accuracy: 0.0188\n",
      "Epoch 134/600\n",
      "32/32 [==============================] - 24s 740ms/step - loss: 0.0777 - accuracy: 0.1867 - val_loss: 2.0836 - val_accuracy: 0.0198\n",
      "Epoch 135/600\n",
      "32/32 [==============================] - 22s 696ms/step - loss: 0.0775 - accuracy: 0.1869 - val_loss: 2.0837 - val_accuracy: 0.0180\n",
      "Epoch 136/600\n",
      "32/32 [==============================] - 21s 645ms/step - loss: 0.0767 - accuracy: 0.1873 - val_loss: 2.0809 - val_accuracy: 0.0178\n",
      "Epoch 137/600\n",
      "32/32 [==============================] - 22s 683ms/step - loss: 0.0748 - accuracy: 0.1872 - val_loss: 2.1060 - val_accuracy: 0.0192\n",
      "Epoch 138/600\n",
      "32/32 [==============================] - 21s 656ms/step - loss: 0.0747 - accuracy: 0.1867 - val_loss: 2.1227 - val_accuracy: 0.0190\n",
      "Epoch 139/600\n",
      "32/32 [==============================] - 23s 731ms/step - loss: 0.0748 - accuracy: 0.1873 - val_loss: 2.1052 - val_accuracy: 0.0192\n",
      "Epoch 140/600\n",
      "32/32 [==============================] - 22s 676ms/step - loss: 0.0715 - accuracy: 0.1877 - val_loss: 2.0999 - val_accuracy: 0.0165\n",
      "Epoch 141/600\n",
      "32/32 [==============================] - 23s 704ms/step - loss: 0.0723 - accuracy: 0.1879 - val_loss: 2.1179 - val_accuracy: 0.0170\n",
      "Epoch 142/600\n",
      "32/32 [==============================] - 23s 725ms/step - loss: 0.0714 - accuracy: 0.1884 - val_loss: 2.1066 - val_accuracy: 0.0182\n",
      "Epoch 143/600\n",
      "32/32 [==============================] - 24s 745ms/step - loss: 0.0713 - accuracy: 0.1871 - val_loss: 2.1159 - val_accuracy: 0.0200\n",
      "Epoch 144/600\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 0.0709 - accuracy: 0.1873 - val_loss: 2.1297 - val_accuracy: 0.0182\n",
      "Epoch 145/600\n",
      "32/32 [==============================] - 19s 592ms/step - loss: 0.0723 - accuracy: 0.1869 - val_loss: 2.1232 - val_accuracy: 0.0188\n",
      "Epoch 146/600\n",
      "32/32 [==============================] - 19s 588ms/step - loss: 0.0665 - accuracy: 0.1887 - val_loss: 2.1298 - val_accuracy: 0.0188\n",
      "Epoch 147/600\n",
      "32/32 [==============================] - 19s 590ms/step - loss: 0.0633 - accuracy: 0.1897 - val_loss: 2.1394 - val_accuracy: 0.0190\n",
      "Epoch 148/600\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 0.0674 - accuracy: 0.1886 - val_loss: 2.1319 - val_accuracy: 0.0188\n",
      "Epoch 149/600\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 0.0717 - accuracy: 0.1884 - val_loss: 2.1266 - val_accuracy: 0.0175\n",
      "Epoch 150/600\n",
      "32/32 [==============================] - 19s 589ms/step - loss: 0.0710 - accuracy: 0.1884 - val_loss: 2.1153 - val_accuracy: 0.0182\n",
      "Epoch 151/600\n",
      "32/32 [==============================] - 20s 610ms/step - loss: 0.0730 - accuracy: 0.1877 - val_loss: 2.1342 - val_accuracy: 0.0198\n",
      "Epoch 152/600\n",
      "32/32 [==============================] - 18s 576ms/step - loss: 0.0677 - accuracy: 0.1891 - val_loss: 2.1147 - val_accuracy: 0.0182\n",
      "Epoch 153/600\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 0.0702 - accuracy: 0.1884 - val_loss: 2.1211 - val_accuracy: 0.0192\n",
      "Epoch 154/600\n",
      "32/32 [==============================] - 20s 612ms/step - loss: 0.0691 - accuracy: 0.1889 - val_loss: 2.1416 - val_accuracy: 0.0195\n",
      "Epoch 155/600\n",
      "32/32 [==============================] - 19s 588ms/step - loss: 0.0659 - accuracy: 0.1890 - val_loss: 2.1431 - val_accuracy: 0.0178\n",
      "Epoch 156/600\n",
      "32/32 [==============================] - 19s 599ms/step - loss: 0.0643 - accuracy: 0.1895 - val_loss: 2.1395 - val_accuracy: 0.0188\n",
      "Epoch 157/600\n",
      "32/32 [==============================] - 22s 678ms/step - loss: 0.0641 - accuracy: 0.1896 - val_loss: 2.1578 - val_accuracy: 0.0195\n",
      "Epoch 158/600\n",
      "32/32 [==============================] - 34s 1s/step - loss: 0.0660 - accuracy: 0.1894 - val_loss: 2.1389 - val_accuracy: 0.0195\n",
      "Epoch 159/600\n",
      "32/32 [==============================] - 25s 791ms/step - loss: 0.0657 - accuracy: 0.1895 - val_loss: 2.1567 - val_accuracy: 0.0175\n",
      "Epoch 160/600\n",
      "32/32 [==============================] - 29s 892ms/step - loss: 0.0645 - accuracy: 0.1904 - val_loss: 2.1444 - val_accuracy: 0.0215\n",
      "Epoch 161/600\n",
      "32/32 [==============================] - 20s 621ms/step - loss: 0.0653 - accuracy: 0.1897 - val_loss: 2.1082 - val_accuracy: 0.0182\n",
      "Epoch 162/600\n",
      "32/32 [==============================] - 20s 636ms/step - loss: 0.0649 - accuracy: 0.1899 - val_loss: 2.1305 - val_accuracy: 0.0190\n",
      "Epoch 163/600\n",
      "32/32 [==============================] - 22s 681ms/step - loss: 0.0621 - accuracy: 0.1899 - val_loss: 2.1353 - val_accuracy: 0.0203\n",
      "Epoch 164/600\n",
      "32/32 [==============================] - 21s 670ms/step - loss: 0.0624 - accuracy: 0.1899 - val_loss: 2.1418 - val_accuracy: 0.0207\n",
      "Epoch 165/600\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 0.0635 - accuracy: 0.1899 - val_loss: 2.1460 - val_accuracy: 0.0200\n",
      "Epoch 166/600\n",
      "32/32 [==============================] - 18s 570ms/step - loss: 0.0608 - accuracy: 0.1908 - val_loss: 2.1324 - val_accuracy: 0.0185\n",
      "Epoch 167/600\n",
      "32/32 [==============================] - 20s 639ms/step - loss: 0.0598 - accuracy: 0.1904 - val_loss: 2.1480 - val_accuracy: 0.0182\n",
      "Epoch 168/600\n",
      "32/32 [==============================] - 20s 638ms/step - loss: 0.0588 - accuracy: 0.1908 - val_loss: 2.1659 - val_accuracy: 0.0170\n",
      "Epoch 169/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 22s 673ms/step - loss: 0.0612 - accuracy: 0.1904 - val_loss: 2.1807 - val_accuracy: 0.0185\n",
      "Epoch 170/600\n",
      "32/32 [==============================] - 20s 637ms/step - loss: 0.0590 - accuracy: 0.1912 - val_loss: 2.1814 - val_accuracy: 0.0185\n",
      "Epoch 171/600\n",
      "32/32 [==============================] - 18s 577ms/step - loss: 0.0576 - accuracy: 0.1917 - val_loss: 2.1699 - val_accuracy: 0.0178\n",
      "Epoch 172/600\n",
      "32/32 [==============================] - 16s 513ms/step - loss: 0.0564 - accuracy: 0.1919 - val_loss: 2.1776 - val_accuracy: 0.0180\n",
      "Epoch 173/600\n",
      "32/32 [==============================] - 20s 611ms/step - loss: 0.0560 - accuracy: 0.1921 - val_loss: 2.1821 - val_accuracy: 0.0188\n",
      "Epoch 174/600\n",
      "32/32 [==============================] - 20s 628ms/step - loss: 0.0562 - accuracy: 0.1927 - val_loss: 2.1733 - val_accuracy: 0.0190\n",
      "Epoch 175/600\n",
      "32/32 [==============================] - 18s 569ms/step - loss: 0.0584 - accuracy: 0.1913 - val_loss: 2.1827 - val_accuracy: 0.0185\n",
      "Epoch 176/600\n",
      "32/32 [==============================] - 19s 579ms/step - loss: 0.0547 - accuracy: 0.1921 - val_loss: 2.1758 - val_accuracy: 0.0178\n",
      "Epoch 177/600\n",
      "32/32 [==============================] - 17s 539ms/step - loss: 0.0538 - accuracy: 0.1916 - val_loss: 2.1911 - val_accuracy: 0.0192\n",
      "Epoch 178/600\n",
      "32/32 [==============================] - 18s 552ms/step - loss: 0.0535 - accuracy: 0.1922 - val_loss: 2.1997 - val_accuracy: 0.0185\n",
      "Epoch 179/600\n",
      "32/32 [==============================] - 24s 748ms/step - loss: 0.0517 - accuracy: 0.1934 - val_loss: 2.1896 - val_accuracy: 0.0185\n",
      "Epoch 180/600\n",
      "32/32 [==============================] - 24s 763ms/step - loss: 0.0555 - accuracy: 0.1918 - val_loss: 2.1890 - val_accuracy: 0.0185\n",
      "Epoch 181/600\n",
      "32/32 [==============================] - 25s 767ms/step - loss: 0.0502 - accuracy: 0.1929 - val_loss: 2.1825 - val_accuracy: 0.0195\n",
      "Epoch 182/600\n",
      "32/32 [==============================] - 28s 861ms/step - loss: 0.0529 - accuracy: 0.1920 - val_loss: 2.2085 - val_accuracy: 0.0200\n",
      "Epoch 183/600\n",
      "32/32 [==============================] - 27s 847ms/step - loss: 0.0512 - accuracy: 0.1931 - val_loss: 2.1872 - val_accuracy: 0.0203\n",
      "Epoch 184/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0527 - accuracy: 0.1930 - val_loss: 2.2121 - val_accuracy: 0.0200\n",
      "Epoch 185/600\n",
      "32/32 [==============================] - 25s 770ms/step - loss: 0.0498 - accuracy: 0.1935 - val_loss: 2.1893 - val_accuracy: 0.0198\n",
      "Epoch 186/600\n",
      "32/32 [==============================] - 24s 765ms/step - loss: 0.0479 - accuracy: 0.1936 - val_loss: 2.2282 - val_accuracy: 0.0195\n",
      "Epoch 187/600\n",
      "32/32 [==============================] - 26s 797ms/step - loss: 0.0473 - accuracy: 0.1938 - val_loss: 2.2059 - val_accuracy: 0.0188\n",
      "Epoch 188/600\n",
      "32/32 [==============================] - 25s 776ms/step - loss: 0.0473 - accuracy: 0.1947 - val_loss: 2.2171 - val_accuracy: 0.0200\n",
      "Epoch 189/600\n",
      "32/32 [==============================] - 24s 758ms/step - loss: 0.0461 - accuracy: 0.1941 - val_loss: 2.2315 - val_accuracy: 0.0205\n",
      "Epoch 190/600\n",
      "32/32 [==============================] - 24s 737ms/step - loss: 0.0466 - accuracy: 0.1941 - val_loss: 2.2230 - val_accuracy: 0.0172\n",
      "Epoch 191/600\n",
      "32/32 [==============================] - 24s 738ms/step - loss: 0.0474 - accuracy: 0.1937 - val_loss: 2.2318 - val_accuracy: 0.0198\n",
      "Epoch 192/600\n",
      "32/32 [==============================] - 24s 739ms/step - loss: 0.0454 - accuracy: 0.1944 - val_loss: 2.2021 - val_accuracy: 0.0195\n",
      "Epoch 193/600\n",
      "32/32 [==============================] - 24s 746ms/step - loss: 0.0438 - accuracy: 0.1956 - val_loss: 2.2167 - val_accuracy: 0.0205\n",
      "Epoch 194/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0437 - accuracy: 0.1953 - val_loss: 2.2224 - val_accuracy: 0.0195\n",
      "Epoch 195/600\n",
      "32/32 [==============================] - 26s 797ms/step - loss: 0.0431 - accuracy: 0.1947 - val_loss: 2.2205 - val_accuracy: 0.0198\n",
      "Epoch 196/600\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.0440 - accuracy: 0.1957 - val_loss: 2.2065 - val_accuracy: 0.0198\n",
      "Epoch 197/600\n",
      "32/32 [==============================] - 25s 768ms/step - loss: 0.0543 - accuracy: 0.1938 - val_loss: 2.2023 - val_accuracy: 0.0185\n",
      "Epoch 198/600\n",
      "32/32 [==============================] - 24s 758ms/step - loss: 0.0547 - accuracy: 0.1941 - val_loss: 2.1821 - val_accuracy: 0.0148\n",
      "Epoch 199/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0471 - accuracy: 0.1942 - val_loss: 2.1954 - val_accuracy: 0.0180\n",
      "Epoch 200/600\n",
      "32/32 [==============================] - 25s 790ms/step - loss: 0.0426 - accuracy: 0.1961 - val_loss: 2.2080 - val_accuracy: 0.0175\n",
      "Epoch 201/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0471 - accuracy: 0.1947 - val_loss: 2.1982 - val_accuracy: 0.0182\n",
      "Epoch 202/600\n",
      "32/32 [==============================] - 30s 923ms/step - loss: 0.0420 - accuracy: 0.1968 - val_loss: 2.1938 - val_accuracy: 0.0198\n",
      "Epoch 203/600\n",
      "32/32 [==============================] - 27s 847ms/step - loss: 0.0416 - accuracy: 0.1956 - val_loss: 2.1954 - val_accuracy: 0.0198\n",
      "Epoch 204/600\n",
      "32/32 [==============================] - 25s 781ms/step - loss: 0.0412 - accuracy: 0.1956 - val_loss: 2.2064 - val_accuracy: 0.0188\n",
      "Epoch 205/600\n",
      "32/32 [==============================] - 24s 745ms/step - loss: 0.0373 - accuracy: 0.1973 - val_loss: 2.2058 - val_accuracy: 0.0188\n",
      "Epoch 206/600\n",
      "32/32 [==============================] - 24s 763ms/step - loss: 0.0361 - accuracy: 0.1976 - val_loss: 2.1956 - val_accuracy: 0.0175\n",
      "Epoch 207/600\n",
      "32/32 [==============================] - 24s 755ms/step - loss: 0.0366 - accuracy: 0.1966 - val_loss: 2.2050 - val_accuracy: 0.0188\n",
      "Epoch 208/600\n",
      "32/32 [==============================] - 24s 764ms/step - loss: 0.0364 - accuracy: 0.1974 - val_loss: 2.1958 - val_accuracy: 0.0200\n",
      "Epoch 209/600\n",
      "32/32 [==============================] - 24s 760ms/step - loss: 0.0351 - accuracy: 0.1979 - val_loss: 2.2182 - val_accuracy: 0.0178\n",
      "Epoch 210/600\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 0.0343 - accuracy: 0.1988 - val_loss: 2.2086 - val_accuracy: 0.0170\n",
      "Epoch 211/600\n",
      "32/32 [==============================] - 25s 787ms/step - loss: 0.0357 - accuracy: 0.1982 - val_loss: 2.2341 - val_accuracy: 0.0185\n",
      "Epoch 212/600\n",
      "32/32 [==============================] - 25s 767ms/step - loss: 0.0369 - accuracy: 0.1977 - val_loss: 2.2158 - val_accuracy: 0.0180\n",
      "Epoch 213/600\n",
      "32/32 [==============================] - 25s 794ms/step - loss: 0.0329 - accuracy: 0.1996 - val_loss: 2.2267 - val_accuracy: 0.0182\n",
      "Epoch 214/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0304 - accuracy: 0.1993 - val_loss: 2.2366 - val_accuracy: 0.0195\n",
      "Epoch 215/600\n",
      "32/32 [==============================] - 29s 902ms/step - loss: 0.0310 - accuracy: 0.1996 - val_loss: 2.2377 - val_accuracy: 0.0160\n",
      "Epoch 216/600\n",
      "32/32 [==============================] - 27s 841ms/step - loss: 0.0324 - accuracy: 0.1991 - val_loss: 2.2362 - val_accuracy: 0.0180\n",
      "Epoch 217/600\n",
      "32/32 [==============================] - 27s 843ms/step - loss: 0.0367 - accuracy: 0.1978 - val_loss: 2.2265 - val_accuracy: 0.0175\n",
      "Epoch 218/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0311 - accuracy: 0.1995 - val_loss: 2.2311 - val_accuracy: 0.0178\n",
      "Epoch 219/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0319 - accuracy: 0.2001 - val_loss: 2.2240 - val_accuracy: 0.0182\n",
      "Epoch 220/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0295 - accuracy: 0.2000 - val_loss: 2.2456 - val_accuracy: 0.0180\n",
      "Epoch 221/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0322 - accuracy: 0.1999 - val_loss: 2.2298 - val_accuracy: 0.0172\n",
      "Epoch 222/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0297 - accuracy: 0.2000 - val_loss: 2.2530 - val_accuracy: 0.0180\n",
      "Epoch 223/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0290 - accuracy: 0.2004 - val_loss: 2.2300 - val_accuracy: 0.0175\n",
      "Epoch 224/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0297 - accuracy: 0.2007 - val_loss: 2.2414 - val_accuracy: 0.0182\n",
      "Epoch 225/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0234 - accuracy: 0.2029 - val_loss: 2.2514 - val_accuracy: 0.0178\n",
      "Epoch 226/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0273 - accuracy: 0.2014 - val_loss: 2.2637 - val_accuracy: 0.0178\n",
      "Epoch 227/600\n",
      "32/32 [==============================] - 27s 840ms/step - loss: 0.0331 - accuracy: 0.2003 - val_loss: 2.2409 - val_accuracy: 0.0178\n",
      "Epoch 228/600\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.0258 - accuracy: 0.2013 - val_loss: 2.2379 - val_accuracy: 0.0195\n",
      "Epoch 229/600\n",
      "32/32 [==============================] - 28s 880ms/step - loss: 0.0300 - accuracy: 0.2001 - val_loss: 2.2629 - val_accuracy: 0.0178\n",
      "Epoch 230/600\n",
      "32/32 [==============================] - 28s 862ms/step - loss: 0.0295 - accuracy: 0.2010 - val_loss: 2.2645 - val_accuracy: 0.0168\n",
      "Epoch 231/600\n",
      "32/32 [==============================] - 27s 852ms/step - loss: 0.0269 - accuracy: 0.2018 - val_loss: 2.2479 - val_accuracy: 0.0188\n",
      "Epoch 232/600\n",
      "32/32 [==============================] - 27s 839ms/step - loss: 0.0252 - accuracy: 0.2021 - val_loss: 2.2829 - val_accuracy: 0.0180\n",
      "Epoch 233/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0258 - accuracy: 0.2017 - val_loss: 2.2956 - val_accuracy: 0.0175\n",
      "Epoch 234/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0255 - accuracy: 0.2021 - val_loss: 2.2544 - val_accuracy: 0.0188\n",
      "Epoch 235/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0232 - accuracy: 0.2027 - val_loss: 2.2886 - val_accuracy: 0.0178\n",
      "Epoch 236/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0214 - accuracy: 0.2027 - val_loss: 2.2802 - val_accuracy: 0.0182\n",
      "Epoch 237/600\n",
      "32/32 [==============================] - 27s 850ms/step - loss: 0.0239 - accuracy: 0.2031 - val_loss: 2.2883 - val_accuracy: 0.0178\n",
      "Epoch 238/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0235 - accuracy: 0.2024 - val_loss: 2.2664 - val_accuracy: 0.0170\n",
      "Epoch 239/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0223 - accuracy: 0.2032 - val_loss: 2.2811 - val_accuracy: 0.0170\n",
      "Epoch 240/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0220 - accuracy: 0.2032 - val_loss: 2.2673 - val_accuracy: 0.0175\n",
      "Epoch 241/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0205 - accuracy: 0.2034 - val_loss: 2.2739 - val_accuracy: 0.0185\n",
      "Epoch 242/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0200 - accuracy: 0.2038 - val_loss: 2.2844 - val_accuracy: 0.0180\n",
      "Epoch 243/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0195 - accuracy: 0.2041 - val_loss: 2.2813 - val_accuracy: 0.0175\n",
      "Epoch 244/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0206 - accuracy: 0.2033 - val_loss: 2.2710 - val_accuracy: 0.0158\n",
      "Epoch 245/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0171 - accuracy: 0.2047 - val_loss: 2.2642 - val_accuracy: 0.0188\n",
      "Epoch 246/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0210 - accuracy: 0.2033 - val_loss: 2.2973 - val_accuracy: 0.0168\n",
      "Epoch 247/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0192 - accuracy: 0.2037 - val_loss: 2.3155 - val_accuracy: 0.0188\n",
      "Epoch 248/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0197 - accuracy: 0.2031 - val_loss: 2.2957 - val_accuracy: 0.0175\n",
      "Epoch 249/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0194 - accuracy: 0.2036 - val_loss: 2.2842 - val_accuracy: 0.0172\n",
      "Epoch 250/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0178 - accuracy: 0.2046 - val_loss: 2.2809 - val_accuracy: 0.0185\n",
      "Epoch 251/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0135 - accuracy: 0.2060 - val_loss: 2.2984 - val_accuracy: 0.0160\n",
      "Epoch 252/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0150 - accuracy: 0.2048 - val_loss: 2.3008 - val_accuracy: 0.0190\n",
      "Epoch 253/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0179 - accuracy: 0.2040 - val_loss: 2.3045 - val_accuracy: 0.0185\n",
      "Epoch 254/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0162 - accuracy: 0.2043 - val_loss: 2.3261 - val_accuracy: 0.0192\n",
      "Epoch 255/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0143 - accuracy: 0.2048 - val_loss: 2.3242 - val_accuracy: 0.0172\n",
      "Epoch 256/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0146 - accuracy: 0.2054 - val_loss: 2.3292 - val_accuracy: 0.0175\n",
      "Epoch 257/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0141 - accuracy: 0.2048 - val_loss: 2.3130 - val_accuracy: 0.0188\n",
      "Epoch 258/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0183 - accuracy: 0.2045 - val_loss: 2.3223 - val_accuracy: 0.0178\n",
      "Epoch 259/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0140 - accuracy: 0.2051 - val_loss: 2.3154 - val_accuracy: 0.0180\n",
      "Epoch 260/600\n",
      "32/32 [==============================] - 25s 792ms/step - loss: 0.0128 - accuracy: 0.2059 - val_loss: 2.3138 - val_accuracy: 0.0198\n",
      "Epoch 261/600\n",
      "32/32 [==============================] - 31s 977ms/step - loss: 0.0122 - accuracy: 0.2052 - val_loss: 2.3053 - val_accuracy: 0.0182\n",
      "Epoch 262/600\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0155 - accuracy: 0.2050 - val_loss: 2.3023 - val_accuracy: 0.0198\n",
      "Epoch 263/600\n",
      "32/32 [==============================] - 27s 851ms/step - loss: 0.0136 - accuracy: 0.2059 - val_loss: 2.3146 - val_accuracy: 0.0200\n",
      "Epoch 264/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0139 - accuracy: 0.2052 - val_loss: 2.3308 - val_accuracy: 0.0182\n",
      "Epoch 265/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0115 - accuracy: 0.2062 - val_loss: 2.3193 - val_accuracy: 0.0178\n",
      "Epoch 266/600\n",
      "32/32 [==============================] - 27s 838ms/step - loss: 0.0153 - accuracy: 0.2048 - val_loss: 2.3140 - val_accuracy: 0.0182\n",
      "Epoch 267/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0139 - accuracy: 0.2053 - val_loss: 2.3082 - val_accuracy: 0.0172\n",
      "Epoch 268/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0111 - accuracy: 0.2058 - val_loss: 2.3362 - val_accuracy: 0.0188\n",
      "Epoch 269/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0109 - accuracy: 0.2068 - val_loss: 2.3523 - val_accuracy: 0.0172\n",
      "Epoch 270/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0114 - accuracy: 0.2062 - val_loss: 2.3324 - val_accuracy: 0.0185\n",
      "Epoch 271/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0102 - accuracy: 0.2067 - val_loss: 2.3130 - val_accuracy: 0.0155\n",
      "Epoch 272/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0110 - accuracy: 0.2068 - val_loss: 2.3414 - val_accuracy: 0.0168\n",
      "Epoch 273/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0150 - accuracy: 0.2051 - val_loss: 2.3257 - val_accuracy: 0.0180\n",
      "Epoch 274/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0118 - accuracy: 0.2063 - val_loss: 2.3438 - val_accuracy: 0.0185\n",
      "Epoch 275/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0099 - accuracy: 0.2068 - val_loss: 2.3045 - val_accuracy: 0.0190\n",
      "Epoch 276/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0100 - accuracy: 0.2066 - val_loss: 2.3241 - val_accuracy: 0.0190\n",
      "Epoch 277/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0116 - accuracy: 0.2062 - val_loss: 2.3209 - val_accuracy: 0.0168\n",
      "Epoch 278/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0100 - accuracy: 0.2064 - val_loss: 2.3214 - val_accuracy: 0.0198\n",
      "Epoch 279/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0123 - accuracy: 0.2059 - val_loss: 2.3165 - val_accuracy: 0.0178\n",
      "Epoch 280/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0105 - accuracy: 0.2061 - val_loss: 2.3210 - val_accuracy: 0.0182\n",
      "Epoch 281/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0111 - accuracy: 0.2058 - val_loss: 2.3155 - val_accuracy: 0.0195\n",
      "Epoch 282/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0104 - accuracy: 0.2061 - val_loss: 2.3100 - val_accuracy: 0.0185\n",
      "Epoch 283/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0125 - accuracy: 0.2058 - val_loss: 2.3118 - val_accuracy: 0.0190\n",
      "Epoch 284/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0067 - accuracy: 0.2072 - val_loss: 2.3253 - val_accuracy: 0.0190\n",
      "Epoch 285/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0106 - accuracy: 0.2063 - val_loss: 2.3375 - val_accuracy: 0.0210\n",
      "Epoch 286/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0091 - accuracy: 0.2069 - val_loss: 2.3257 - val_accuracy: 0.0185\n",
      "Epoch 287/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0093 - accuracy: 0.2067 - val_loss: 2.3415 - val_accuracy: 0.0195\n",
      "Epoch 288/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0097 - accuracy: 0.2065 - val_loss: 2.3201 - val_accuracy: 0.0205\n",
      "Epoch 289/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0091 - accuracy: 0.2070 - val_loss: 2.3242 - val_accuracy: 0.0192\n",
      "Epoch 290/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0084 - accuracy: 0.2069 - val_loss: 2.3298 - val_accuracy: 0.0203\n",
      "Epoch 291/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0087 - accuracy: 0.2069 - val_loss: 2.3260 - val_accuracy: 0.0203\n",
      "Epoch 292/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0073 - accuracy: 0.2075 - val_loss: 2.3261 - val_accuracy: 0.0172\n",
      "Epoch 293/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0074 - accuracy: 0.2072 - val_loss: 2.3438 - val_accuracy: 0.0168\n",
      "Epoch 294/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0071 - accuracy: 0.2074 - val_loss: 2.3500 - val_accuracy: 0.0180\n",
      "Epoch 295/600\n",
      "32/32 [==============================] - 28s 864ms/step - loss: 0.0068 - accuracy: 0.2075 - val_loss: 2.3468 - val_accuracy: 0.0192\n",
      "Epoch 296/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0125 - accuracy: 0.2059 - val_loss: 2.3198 - val_accuracy: 0.0185\n",
      "Epoch 297/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0081 - accuracy: 0.2068 - val_loss: 2.3332 - val_accuracy: 0.0198\n",
      "Epoch 298/600\n",
      "32/32 [==============================] - 27s 843ms/step - loss: 0.0068 - accuracy: 0.2077 - val_loss: 2.3297 - val_accuracy: 0.0205\n",
      "Epoch 299/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0079 - accuracy: 0.2074 - val_loss: 2.3216 - val_accuracy: 0.0205\n",
      "Epoch 300/600\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.0077 - accuracy: 0.2068 - val_loss: 2.3315 - val_accuracy: 0.0172\n",
      "Epoch 301/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0114 - accuracy: 0.2064 - val_loss: 2.3415 - val_accuracy: 0.0190\n",
      "Epoch 302/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0049 - accuracy: 0.2081 - val_loss: 2.3447 - val_accuracy: 0.0175\n",
      "Epoch 303/600\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 0.0056 - accuracy: 0.2076 - val_loss: 2.3532 - val_accuracy: 0.0185\n",
      "Epoch 304/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0072 - accuracy: 0.2071 - val_loss: 2.3378 - val_accuracy: 0.0182\n",
      "Epoch 305/600\n",
      "32/32 [==============================] - 27s 842ms/step - loss: 0.0066 - accuracy: 0.2072 - val_loss: 2.3502 - val_accuracy: 0.0192\n",
      "Epoch 306/600\n",
      "32/32 [==============================] - 27s 840ms/step - loss: 0.0050 - accuracy: 0.2080 - val_loss: 2.3405 - val_accuracy: 0.0213\n",
      "Epoch 307/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0062 - accuracy: 0.2070 - val_loss: 2.3561 - val_accuracy: 0.0185\n",
      "Epoch 308/600\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.0096 - accuracy: 0.2068 - val_loss: 2.3302 - val_accuracy: 0.0175\n",
      "Epoch 309/600\n",
      "32/32 [==============================] - 27s 837ms/step - loss: 0.0042 - accuracy: 0.2083 - val_loss: 2.3535 - val_accuracy: 0.0175\n",
      "Epoch 310/600\n",
      "32/32 [==============================] - 27s 846ms/step - loss: 0.0060 - accuracy: 0.2078 - val_loss: 2.3512 - val_accuracy: 0.0182\n",
      "Epoch 311/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0074 - accuracy: 0.2069 - val_loss: 2.3611 - val_accuracy: 0.0175\n",
      "Epoch 312/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0047 - accuracy: 0.2079 - val_loss: 2.3751 - val_accuracy: 0.0203\n",
      "Epoch 313/600\n",
      "32/32 [==============================] - 27s 833ms/step - loss: 0.0049 - accuracy: 0.2081 - val_loss: 2.3730 - val_accuracy: 0.0180\n",
      "Epoch 314/600\n",
      "32/32 [==============================] - 27s 857ms/step - loss: 0.0027 - accuracy: 0.2083 - val_loss: 2.3596 - val_accuracy: 0.0182\n",
      "Epoch 315/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0041 - accuracy: 0.2079 - val_loss: 2.3719 - val_accuracy: 0.0198\n",
      "Epoch 316/600\n",
      "32/32 [==============================] - 27s 843ms/step - loss: 0.0051 - accuracy: 0.2076 - val_loss: 2.3647 - val_accuracy: 0.0195\n",
      "Epoch 317/600\n",
      "32/32 [==============================] - 27s 837ms/step - loss: 0.0050 - accuracy: 0.2080 - val_loss: 2.3643 - val_accuracy: 0.0170\n",
      "Epoch 318/600\n",
      "32/32 [==============================] - 27s 845ms/step - loss: 0.0040 - accuracy: 0.2080 - val_loss: 2.3741 - val_accuracy: 0.0192\n",
      "Epoch 319/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0048 - accuracy: 0.2081 - val_loss: 2.3546 - val_accuracy: 0.0170\n",
      "Epoch 320/600\n",
      "32/32 [==============================] - 27s 842ms/step - loss: 0.0145 - accuracy: 0.2054 - val_loss: 2.3589 - val_accuracy: 0.0178\n",
      "Epoch 321/600\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 0.0097 - accuracy: 0.2071 - val_loss: 2.3702 - val_accuracy: 0.0178\n",
      "Epoch 322/600\n",
      "32/32 [==============================] - 173s 5s/step - loss: 0.0049 - accuracy: 0.2079 - val_loss: 2.3743 - val_accuracy: 0.0178\n",
      "Epoch 323/600\n",
      "32/32 [==============================] - 22s 691ms/step - loss: 0.0068 - accuracy: 0.2075 - val_loss: 2.3820 - val_accuracy: 0.0175\n",
      "Epoch 324/600\n",
      "32/32 [==============================] - 21s 648ms/step - loss: 0.0063 - accuracy: 0.2076 - val_loss: 2.3863 - val_accuracy: 0.0168\n",
      "Epoch 325/600\n",
      "32/32 [==============================] - 23s 725ms/step - loss: 0.0078 - accuracy: 0.2070 - val_loss: 2.3846 - val_accuracy: 0.0162\n",
      "Epoch 326/600\n",
      "32/32 [==============================] - 24s 755ms/step - loss: 0.0066 - accuracy: 0.2076 - val_loss: 2.3858 - val_accuracy: 0.0182\n",
      "Epoch 327/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0042 - accuracy: 0.2083 - val_loss: 2.3793 - val_accuracy: 0.0180\n",
      "Epoch 328/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0053 - accuracy: 0.2078 - val_loss: 2.3822 - val_accuracy: 0.0175\n",
      "Epoch 329/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0035 - accuracy: 0.2083 - val_loss: 2.3835 - val_accuracy: 0.0178\n",
      "Epoch 330/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0037 - accuracy: 0.2081 - val_loss: 2.3957 - val_accuracy: 0.0178\n",
      "Epoch 331/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0050 - accuracy: 0.2077 - val_loss: 2.3513 - val_accuracy: 0.0190\n",
      "Epoch 332/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0028 - accuracy: 0.2083 - val_loss: 2.3683 - val_accuracy: 0.0172\n",
      "Epoch 333/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0026 - accuracy: 0.2084 - val_loss: 2.3724 - val_accuracy: 0.0180\n",
      "Epoch 334/600\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 0.0049 - accuracy: 0.2079 - val_loss: 2.3860 - val_accuracy: 0.0170\n",
      "Epoch 335/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0029 - accuracy: 0.2083 - val_loss: 2.3730 - val_accuracy: 0.0182\n",
      "Epoch 336/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0071 - accuracy: 0.2072 - val_loss: 2.3860 - val_accuracy: 0.0180\n",
      "Epoch 337/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0091 - accuracy: 0.2072 - val_loss: 2.3776 - val_accuracy: 0.0192\n",
      "Epoch 338/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0059 - accuracy: 0.2078 - val_loss: 2.3627 - val_accuracy: 0.0192\n",
      "Epoch 339/600\n",
      "32/32 [==============================] - 27s 841ms/step - loss: 0.0058 - accuracy: 0.2077 - val_loss: 2.3887 - val_accuracy: 0.0192\n",
      "Epoch 340/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0050 - accuracy: 0.2079 - val_loss: 2.3969 - val_accuracy: 0.0182\n",
      "Epoch 341/600\n",
      "32/32 [==============================] - 26s 827ms/step - loss: 0.0061 - accuracy: 0.2074 - val_loss: 2.4031 - val_accuracy: 0.0175\n",
      "Epoch 342/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0060 - accuracy: 0.2076 - val_loss: 2.3948 - val_accuracy: 0.0168\n",
      "Epoch 343/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0057 - accuracy: 0.2075 - val_loss: 2.3937 - val_accuracy: 0.0190\n",
      "Epoch 344/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0054 - accuracy: 0.2078 - val_loss: 2.3917 - val_accuracy: 0.0195\n",
      "Epoch 345/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0077 - accuracy: 0.2072 - val_loss: 2.4012 - val_accuracy: 0.0160\n",
      "Epoch 346/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0082 - accuracy: 0.2076 - val_loss: 2.3871 - val_accuracy: 0.0182\n",
      "Epoch 347/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0017 - accuracy: 0.2086 - val_loss: 2.3901 - val_accuracy: 0.0172\n",
      "Epoch 348/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0031 - accuracy: 0.2081 - val_loss: 2.3923 - val_accuracy: 0.0182\n",
      "Epoch 349/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0024 - accuracy: 0.2084 - val_loss: 2.3875 - val_accuracy: 0.0200\n",
      "Epoch 350/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0040 - accuracy: 0.2084 - val_loss: 2.4019 - val_accuracy: 0.0192\n",
      "Epoch 351/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0064 - accuracy: 0.2077 - val_loss: 2.3958 - val_accuracy: 0.0175\n",
      "Epoch 352/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0026 - accuracy: 0.2086 - val_loss: 2.3928 - val_accuracy: 0.0182\n",
      "Epoch 353/600\n",
      "32/32 [==============================] - 27s 842ms/step - loss: 0.0027 - accuracy: 0.2083 - val_loss: 2.4012 - val_accuracy: 0.0182\n",
      "Epoch 354/600\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.0039 - accuracy: 0.2079 - val_loss: 2.4004 - val_accuracy: 0.0188\n",
      "Epoch 355/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0061 - accuracy: 0.2075 - val_loss: 2.3955 - val_accuracy: 0.0170\n",
      "Epoch 356/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0050 - accuracy: 0.2076 - val_loss: 2.4077 - val_accuracy: 0.0170\n",
      "Epoch 357/600\n",
      "32/32 [==============================] - 27s 837ms/step - loss: 0.0023 - accuracy: 0.2086 - val_loss: 2.3932 - val_accuracy: 0.0190\n",
      "Epoch 358/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0033 - accuracy: 0.2083 - val_loss: 2.4192 - val_accuracy: 0.0170\n",
      "Epoch 359/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0060 - accuracy: 0.2074 - val_loss: 2.4026 - val_accuracy: 0.0180\n",
      "Epoch 360/600\n",
      "32/32 [==============================] - 27s 840ms/step - loss: 0.0071 - accuracy: 0.2071 - val_loss: 2.3867 - val_accuracy: 0.0182\n",
      "Epoch 361/600\n",
      "32/32 [==============================] - 27s 845ms/step - loss: 0.0049 - accuracy: 0.2078 - val_loss: 2.3975 - val_accuracy: 0.0198\n",
      "Epoch 362/600\n",
      "32/32 [==============================] - 27s 843ms/step - loss: 0.0041 - accuracy: 0.2080 - val_loss: 2.4062 - val_accuracy: 0.0190\n",
      "Epoch 363/600\n",
      "32/32 [==============================] - 27s 843ms/step - loss: 0.0017 - accuracy: 0.2087 - val_loss: 2.3849 - val_accuracy: 0.0207\n",
      "Epoch 364/600\n",
      "32/32 [==============================] - 29s 898ms/step - loss: 0.0026 - accuracy: 0.2083 - val_loss: 2.4007 - val_accuracy: 0.0188\n",
      "Epoch 365/600\n",
      "32/32 [==============================] - 27s 851ms/step - loss: 0.0037 - accuracy: 0.2079 - val_loss: 2.3900 - val_accuracy: 0.0182\n",
      "Epoch 366/600\n",
      "32/32 [==============================] - 27s 836ms/step - loss: 0.0043 - accuracy: 0.2077 - val_loss: 2.3889 - val_accuracy: 0.0192\n",
      "Epoch 367/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0042 - accuracy: 0.2079 - val_loss: 2.3921 - val_accuracy: 0.0170\n",
      "Epoch 368/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0024 - accuracy: 0.2082 - val_loss: 2.4044 - val_accuracy: 0.0198\n",
      "Epoch 369/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0021 - accuracy: 0.2085 - val_loss: 2.3776 - val_accuracy: 0.0182\n",
      "Epoch 370/600\n",
      "32/32 [==============================] - 27s 839ms/step - loss: 0.0039 - accuracy: 0.2079 - val_loss: 2.3985 - val_accuracy: 0.0180\n",
      "Epoch 371/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0033 - accuracy: 0.2083 - val_loss: 2.4117 - val_accuracy: 0.0192\n",
      "Epoch 372/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0067 - accuracy: 0.2074 - val_loss: 2.4033 - val_accuracy: 0.0188\n",
      "Epoch 373/600\n",
      "32/32 [==============================] - 26s 806ms/step - loss: 0.0030 - accuracy: 0.2083 - val_loss: 2.4188 - val_accuracy: 0.0165\n",
      "Epoch 374/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0047 - accuracy: 0.2078 - val_loss: 2.4210 - val_accuracy: 0.0198\n",
      "Epoch 375/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0035 - accuracy: 0.2079 - val_loss: 2.4264 - val_accuracy: 0.0190\n",
      "Epoch 376/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0048 - accuracy: 0.2081 - val_loss: 2.4302 - val_accuracy: 0.0165\n",
      "Epoch 377/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0026 - accuracy: 0.2081 - val_loss: 2.4261 - val_accuracy: 0.0178\n",
      "Epoch 378/600\n",
      "32/32 [==============================] - 26s 798ms/step - loss: 0.0031 - accuracy: 0.2084 - val_loss: 2.4148 - val_accuracy: 0.0190\n",
      "Epoch 379/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0067 - accuracy: 0.2077 - val_loss: 2.4212 - val_accuracy: 0.0185\n",
      "Epoch 380/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0052 - accuracy: 0.2077 - val_loss: 2.3931 - val_accuracy: 0.0188\n",
      "Epoch 381/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4253 - val_accuracy: 0.0200\n",
      "Epoch 382/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0035 - accuracy: 0.2079 - val_loss: 2.4218 - val_accuracy: 0.0182\n",
      "Epoch 383/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0021 - accuracy: 0.2083 - val_loss: 2.4401 - val_accuracy: 0.0172\n",
      "Epoch 384/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0043 - accuracy: 0.2081 - val_loss: 2.4433 - val_accuracy: 0.0175\n",
      "Epoch 385/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0031 - accuracy: 0.2084 - val_loss: 2.4311 - val_accuracy: 0.0188\n",
      "Epoch 386/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0036 - accuracy: 0.2080 - val_loss: 2.3993 - val_accuracy: 0.0162\n",
      "Epoch 387/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0049 - accuracy: 0.2077 - val_loss: 2.4222 - val_accuracy: 0.0170\n",
      "Epoch 388/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0011 - accuracy: 0.2087 - val_loss: 2.4376 - val_accuracy: 0.0178\n",
      "Epoch 389/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0012 - accuracy: 0.2087 - val_loss: 2.4125 - val_accuracy: 0.0153\n",
      "Epoch 390/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0017 - accuracy: 0.2084 - val_loss: 2.4190 - val_accuracy: 0.0180\n",
      "Epoch 391/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0025 - accuracy: 0.2083 - val_loss: 2.4470 - val_accuracy: 0.0168\n",
      "Epoch 392/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0043 - accuracy: 0.2076 - val_loss: 2.4306 - val_accuracy: 0.0172\n",
      "Epoch 393/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0031 - accuracy: 0.2082 - val_loss: 2.4186 - val_accuracy: 0.0175\n",
      "Epoch 394/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0027 - accuracy: 0.2083 - val_loss: 2.4274 - val_accuracy: 0.0162\n",
      "Epoch 395/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0026 - accuracy: 0.2084 - val_loss: 2.4207 - val_accuracy: 0.0178\n",
      "Epoch 396/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0019 - accuracy: 0.2086 - val_loss: 2.4597 - val_accuracy: 0.0168\n",
      "Epoch 397/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0031 - accuracy: 0.2084 - val_loss: 2.4286 - val_accuracy: 0.0182\n",
      "Epoch 398/600\n",
      "32/32 [==============================] - 26s 803ms/step - loss: 0.0020 - accuracy: 0.2085 - val_loss: 2.4530 - val_accuracy: 0.0172\n",
      "Epoch 399/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0025 - accuracy: 0.2085 - val_loss: 2.4376 - val_accuracy: 0.0172\n",
      "Epoch 400/600\n",
      "32/32 [==============================] - 26s 804ms/step - loss: 0.0013 - accuracy: 0.2086 - val_loss: 2.4322 - val_accuracy: 0.0170\n",
      "Epoch 401/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0045 - accuracy: 0.2078 - val_loss: 2.4183 - val_accuracy: 0.0172\n",
      "Epoch 402/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0032 - accuracy: 0.2082 - val_loss: 2.4366 - val_accuracy: 0.0165\n",
      "Epoch 403/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0012 - accuracy: 0.2087 - val_loss: 2.4490 - val_accuracy: 0.0172\n",
      "Epoch 404/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0021 - accuracy: 0.2085 - val_loss: 2.4477 - val_accuracy: 0.0172\n",
      "Epoch 405/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0035 - accuracy: 0.2079 - val_loss: 2.4301 - val_accuracy: 0.0175\n",
      "Epoch 406/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0044 - accuracy: 0.2081 - val_loss: 2.4211 - val_accuracy: 0.0200\n",
      "Epoch 407/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0034 - accuracy: 0.2081 - val_loss: 2.4298 - val_accuracy: 0.0180\n",
      "Epoch 408/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0020 - accuracy: 0.2086 - val_loss: 2.4205 - val_accuracy: 0.0180\n",
      "Epoch 409/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0021 - accuracy: 0.2084 - val_loss: 2.4391 - val_accuracy: 0.0192\n",
      "Epoch 410/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0054 - accuracy: 0.2079 - val_loss: 2.4284 - val_accuracy: 0.0178\n",
      "Epoch 411/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0033 - accuracy: 0.2082 - val_loss: 2.4244 - val_accuracy: 0.0200\n",
      "Epoch 412/600\n",
      "32/32 [==============================] - 26s 805ms/step - loss: 0.0030 - accuracy: 0.2081 - val_loss: 2.4249 - val_accuracy: 0.0188\n",
      "Epoch 413/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0038 - accuracy: 0.2079 - val_loss: 2.4270 - val_accuracy: 0.0188\n",
      "Epoch 414/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0021 - accuracy: 0.2084 - val_loss: 2.4501 - val_accuracy: 0.0182\n",
      "Epoch 415/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0014 - accuracy: 0.2087 - val_loss: 2.4284 - val_accuracy: 0.0178\n",
      "Epoch 416/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4256 - val_accuracy: 0.0180\n",
      "Epoch 417/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0034 - accuracy: 0.2078 - val_loss: 2.4395 - val_accuracy: 0.0170\n",
      "Epoch 418/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0032 - accuracy: 0.2081 - val_loss: 2.4489 - val_accuracy: 0.0178\n",
      "Epoch 419/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4383 - val_accuracy: 0.0178\n",
      "Epoch 420/600\n",
      "32/32 [==============================] - 27s 841ms/step - loss: 0.0026 - accuracy: 0.2083 - val_loss: 2.4297 - val_accuracy: 0.0182\n",
      "Epoch 421/600\n",
      "32/32 [==============================] - 29s 903ms/step - loss: 0.0039 - accuracy: 0.2079 - val_loss: 2.4717 - val_accuracy: 0.0160\n",
      "Epoch 422/600\n",
      "32/32 [==============================] - 27s 852ms/step - loss: 0.0047 - accuracy: 0.2080 - val_loss: 2.4632 - val_accuracy: 0.0185\n",
      "Epoch 423/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0028 - accuracy: 0.2081 - val_loss: 2.4609 - val_accuracy: 0.0180\n",
      "Epoch 424/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0042 - accuracy: 0.2078 - val_loss: 2.4583 - val_accuracy: 0.0162\n",
      "Epoch 425/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0021 - accuracy: 0.2084 - val_loss: 2.4235 - val_accuracy: 0.0170\n",
      "Epoch 426/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0036 - accuracy: 0.2081 - val_loss: 2.4599 - val_accuracy: 0.0160\n",
      "Epoch 427/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0020 - accuracy: 0.2083 - val_loss: 2.4312 - val_accuracy: 0.0178\n",
      "Epoch 428/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0018 - accuracy: 0.2086 - val_loss: 2.4541 - val_accuracy: 0.0180\n",
      "Epoch 429/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0025 - accuracy: 0.2083 - val_loss: 2.4660 - val_accuracy: 0.0172\n",
      "Epoch 430/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0058 - accuracy: 0.2076 - val_loss: 2.4478 - val_accuracy: 0.0185\n",
      "Epoch 431/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0055 - accuracy: 0.2077 - val_loss: 2.4656 - val_accuracy: 0.0182\n",
      "Epoch 432/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0035 - accuracy: 0.2081 - val_loss: 2.4681 - val_accuracy: 0.0185\n",
      "Epoch 433/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0028 - accuracy: 0.2086 - val_loss: 2.4573 - val_accuracy: 0.0203\n",
      "Epoch 434/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0032 - accuracy: 0.2081 - val_loss: 2.4578 - val_accuracy: 0.0185\n",
      "Epoch 435/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0020 - accuracy: 0.2084 - val_loss: 2.4285 - val_accuracy: 0.0182\n",
      "Epoch 436/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0045 - accuracy: 0.2083 - val_loss: 2.4412 - val_accuracy: 0.0170\n",
      "Epoch 437/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0037 - accuracy: 0.2084 - val_loss: 2.4385 - val_accuracy: 0.0182\n",
      "Epoch 438/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0049 - accuracy: 0.2078 - val_loss: 2.4379 - val_accuracy: 0.0180\n",
      "Epoch 439/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0040 - accuracy: 0.2081 - val_loss: 2.4340 - val_accuracy: 0.0182\n",
      "Epoch 440/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0017 - accuracy: 0.2086 - val_loss: 2.4320 - val_accuracy: 0.0185\n",
      "Epoch 441/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0046 - accuracy: 0.2077 - val_loss: 2.4382 - val_accuracy: 0.0198\n",
      "Epoch 442/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0020 - accuracy: 0.2085 - val_loss: 2.4556 - val_accuracy: 0.0182\n",
      "Epoch 443/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0044 - accuracy: 0.2075 - val_loss: 2.4053 - val_accuracy: 0.0188\n",
      "Epoch 444/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0045 - accuracy: 0.2079 - val_loss: 2.4166 - val_accuracy: 0.0178\n",
      "Epoch 445/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0030 - accuracy: 0.2084 - val_loss: 2.4183 - val_accuracy: 0.0185\n",
      "Epoch 446/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0035 - accuracy: 0.2081 - val_loss: 2.4082 - val_accuracy: 0.0195\n",
      "Epoch 447/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0034 - accuracy: 0.2081 - val_loss: 2.4381 - val_accuracy: 0.0188\n",
      "Epoch 448/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0013 - accuracy: 0.2087 - val_loss: 2.4292 - val_accuracy: 0.0200\n",
      "Epoch 449/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0012 - accuracy: 0.2089 - val_loss: 2.4472 - val_accuracy: 0.0198\n",
      "Epoch 450/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0023 - accuracy: 0.2083 - val_loss: 2.4425 - val_accuracy: 0.0195\n",
      "Epoch 451/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0014 - accuracy: 0.2085 - val_loss: 2.4487 - val_accuracy: 0.0188\n",
      "Epoch 452/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0016 - accuracy: 0.2084 - val_loss: 2.4516 - val_accuracy: 0.0185\n",
      "Epoch 453/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0059 - accuracy: 0.2078 - val_loss: 2.4372 - val_accuracy: 0.0190\n",
      "Epoch 454/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0018 - accuracy: 0.2085 - val_loss: 2.4884 - val_accuracy: 0.0178\n",
      "Epoch 455/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0016 - accuracy: 0.2086 - val_loss: 2.4822 - val_accuracy: 0.0188\n",
      "Epoch 456/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0026 - accuracy: 0.2084 - val_loss: 2.4779 - val_accuracy: 0.0200\n",
      "Epoch 457/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0032 - accuracy: 0.2084 - val_loss: 2.4568 - val_accuracy: 0.0200\n",
      "Epoch 458/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0073 - accuracy: 0.2076 - val_loss: 2.4593 - val_accuracy: 0.0195\n",
      "Epoch 459/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0013 - accuracy: 0.2086 - val_loss: 2.4647 - val_accuracy: 0.0190\n",
      "Epoch 460/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0017 - accuracy: 0.2087 - val_loss: 2.4643 - val_accuracy: 0.0178\n",
      "Epoch 461/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.4653 - val_accuracy: 0.0178\n",
      "Epoch 462/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0017 - accuracy: 0.2086 - val_loss: 2.4699 - val_accuracy: 0.0203\n",
      "Epoch 463/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0044 - accuracy: 0.2083 - val_loss: 2.4560 - val_accuracy: 0.0168\n",
      "Epoch 464/600\n",
      "32/32 [==============================] - 26s 806ms/step - loss: 0.0034 - accuracy: 0.2083 - val_loss: 2.4994 - val_accuracy: 0.0180\n",
      "Epoch 465/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0016 - accuracy: 0.2084 - val_loss: 2.4701 - val_accuracy: 0.0172\n",
      "Epoch 466/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0023 - accuracy: 0.2085 - val_loss: 2.4843 - val_accuracy: 0.0168\n",
      "Epoch 467/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0013 - accuracy: 0.2087 - val_loss: 2.4872 - val_accuracy: 0.0180\n",
      "Epoch 468/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.4881 - val_accuracy: 0.0190\n",
      "Epoch 469/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0019 - accuracy: 0.2084 - val_loss: 2.4836 - val_accuracy: 0.0178\n",
      "Epoch 470/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0020 - accuracy: 0.2086 - val_loss: 2.4793 - val_accuracy: 0.0192\n",
      "Epoch 471/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0018 - accuracy: 0.2086 - val_loss: 2.4629 - val_accuracy: 0.0172\n",
      "Epoch 472/600\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.0013 - accuracy: 0.2085 - val_loss: 2.4684 - val_accuracy: 0.0185\n",
      "Epoch 473/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0022 - accuracy: 0.2085 - val_loss: 2.4911 - val_accuracy: 0.0190\n",
      "Epoch 474/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0023 - accuracy: 0.2085 - val_loss: 2.4775 - val_accuracy: 0.0180\n",
      "Epoch 475/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0037 - accuracy: 0.2078 - val_loss: 2.4839 - val_accuracy: 0.0182\n",
      "Epoch 476/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0023 - accuracy: 0.2084 - val_loss: 2.4715 - val_accuracy: 0.0185\n",
      "Epoch 477/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4969 - val_accuracy: 0.0165\n",
      "Epoch 478/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.4902 - val_accuracy: 0.0150\n",
      "Epoch 479/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0026 - accuracy: 0.2080 - val_loss: 2.4886 - val_accuracy: 0.0185\n",
      "Epoch 480/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0024 - accuracy: 0.2084 - val_loss: 2.4751 - val_accuracy: 0.0175\n",
      "Epoch 481/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0028 - accuracy: 0.2084 - val_loss: 2.4900 - val_accuracy: 0.0160\n",
      "Epoch 482/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0019 - accuracy: 0.2084 - val_loss: 2.4823 - val_accuracy: 0.0182\n",
      "Epoch 483/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0044 - accuracy: 0.2079 - val_loss: 2.4859 - val_accuracy: 0.0172\n",
      "Epoch 484/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0032 - accuracy: 0.2081 - val_loss: 2.4752 - val_accuracy: 0.0168\n",
      "Epoch 485/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0023 - accuracy: 0.2086 - val_loss: 2.4847 - val_accuracy: 0.0170\n",
      "Epoch 486/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0010 - accuracy: 0.2087 - val_loss: 2.4805 - val_accuracy: 0.0158\n",
      "Epoch 487/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0018 - accuracy: 0.2085 - val_loss: 2.5061 - val_accuracy: 0.0172\n",
      "Epoch 488/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0039 - accuracy: 0.2079 - val_loss: 2.4829 - val_accuracy: 0.0180\n",
      "Epoch 489/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0026 - accuracy: 0.2083 - val_loss: 2.4808 - val_accuracy: 0.0195\n",
      "Epoch 490/600\n",
      "32/32 [==============================] - 27s 838ms/step - loss: 0.0036 - accuracy: 0.2080 - val_loss: 2.4941 - val_accuracy: 0.0175\n",
      "Epoch 491/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0043 - accuracy: 0.2082 - val_loss: 2.4810 - val_accuracy: 0.0172\n",
      "Epoch 492/600\n",
      "32/32 [==============================] - 27s 836ms/step - loss: 0.0029 - accuracy: 0.2083 - val_loss: 2.4833 - val_accuracy: 0.0180\n",
      "Epoch 493/600\n",
      "32/32 [==============================] - 28s 864ms/step - loss: 0.0022 - accuracy: 0.2086 - val_loss: 2.4811 - val_accuracy: 0.0175\n",
      "Epoch 494/600\n",
      "32/32 [==============================] - 32s 1s/step - loss: 0.0028 - accuracy: 0.2085 - val_loss: 2.4864 - val_accuracy: 0.0203\n",
      "Epoch 495/600\n",
      "32/32 [==============================] - 28s 886ms/step - loss: 0.0040 - accuracy: 0.2084 - val_loss: 2.4824 - val_accuracy: 0.0190\n",
      "Epoch 496/600\n",
      "32/32 [==============================] - 28s 869ms/step - loss: 0.0038 - accuracy: 0.2079 - val_loss: 2.4748 - val_accuracy: 0.0203\n",
      "Epoch 497/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0020 - accuracy: 0.2083 - val_loss: 2.4896 - val_accuracy: 0.0192\n",
      "Epoch 498/600\n",
      "32/32 [==============================] - 30s 937ms/step - loss: 0.0053 - accuracy: 0.2082 - val_loss: 2.4868 - val_accuracy: 0.0180\n",
      "Epoch 499/600\n",
      "32/32 [==============================] - 27s 850ms/step - loss: 0.0037 - accuracy: 0.2079 - val_loss: 2.4784 - val_accuracy: 0.0172\n",
      "Epoch 500/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4842 - val_accuracy: 0.0175\n",
      "Epoch 501/600\n",
      "32/32 [==============================] - 27s 834ms/step - loss: 0.0039 - accuracy: 0.2079 - val_loss: 2.4802 - val_accuracy: 0.0162\n",
      "Epoch 502/600\n",
      "32/32 [==============================] - 27s 831ms/step - loss: 0.0033 - accuracy: 0.2084 - val_loss: 2.4610 - val_accuracy: 0.0198\n",
      "Epoch 503/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0056 - accuracy: 0.2078 - val_loss: 2.4798 - val_accuracy: 0.0168\n",
      "Epoch 504/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0023 - accuracy: 0.2085 - val_loss: 2.4563 - val_accuracy: 0.0182\n",
      "Epoch 505/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0030 - accuracy: 0.2087 - val_loss: 2.4675 - val_accuracy: 0.0178\n",
      "Epoch 506/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0014 - accuracy: 0.2087 - val_loss: 2.4709 - val_accuracy: 0.0188\n",
      "Epoch 507/600\n",
      "32/32 [==============================] - 27s 830ms/step - loss: 0.0012 - accuracy: 0.2087 - val_loss: 2.4797 - val_accuracy: 0.0192\n",
      "Epoch 508/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0026 - accuracy: 0.2086 - val_loss: 2.4911 - val_accuracy: 0.0180\n",
      "Epoch 509/600\n",
      "32/32 [==============================] - 27s 833ms/step - loss: 0.0043 - accuracy: 0.2081 - val_loss: 2.4848 - val_accuracy: 0.0182\n",
      "Epoch 510/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0030 - accuracy: 0.2085 - val_loss: 2.4843 - val_accuracy: 0.0190\n",
      "Epoch 511/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0028 - accuracy: 0.2084 - val_loss: 2.5200 - val_accuracy: 0.0175\n",
      "Epoch 512/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0022 - accuracy: 0.2085 - val_loss: 2.5038 - val_accuracy: 0.0172\n",
      "Epoch 513/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0018 - accuracy: 0.2084 - val_loss: 2.5003 - val_accuracy: 0.0205\n",
      "Epoch 514/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0030 - accuracy: 0.2085 - val_loss: 2.5032 - val_accuracy: 0.0180\n",
      "Epoch 515/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0020 - accuracy: 0.2084 - val_loss: 2.5104 - val_accuracy: 0.0185\n",
      "Epoch 516/600\n",
      "32/32 [==============================] - 27s 835ms/step - loss: 0.0018 - accuracy: 0.2084 - val_loss: 2.4900 - val_accuracy: 0.0180\n",
      "Epoch 517/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0019 - accuracy: 0.2085 - val_loss: 2.5035 - val_accuracy: 0.0185\n",
      "Epoch 518/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0013 - accuracy: 0.2086 - val_loss: 2.5087 - val_accuracy: 0.0178\n",
      "Epoch 519/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0017 - accuracy: 0.2086 - val_loss: 2.5039 - val_accuracy: 0.0190\n",
      "Epoch 520/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0017 - accuracy: 0.2085 - val_loss: 2.5025 - val_accuracy: 0.0195\n",
      "Epoch 521/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0011 - accuracy: 0.2087 - val_loss: 2.5062 - val_accuracy: 0.0188\n",
      "Epoch 522/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0011 - accuracy: 0.2086 - val_loss: 2.5029 - val_accuracy: 0.0195\n",
      "Epoch 523/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0019 - accuracy: 0.2086 - val_loss: 2.4905 - val_accuracy: 0.0182\n",
      "Epoch 524/600\n",
      "32/32 [==============================] - 26s 819ms/step - loss: 0.0023 - accuracy: 0.2084 - val_loss: 2.5150 - val_accuracy: 0.0168\n",
      "Epoch 525/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0217 - accuracy: 0.2052 - val_loss: 2.5224 - val_accuracy: 0.0158\n",
      "Epoch 526/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0058 - accuracy: 0.2077 - val_loss: 2.5156 - val_accuracy: 0.0168\n",
      "Epoch 527/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0035 - accuracy: 0.2083 - val_loss: 2.5213 - val_accuracy: 0.0162\n",
      "Epoch 528/600\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 0.0049 - accuracy: 0.2079 - val_loss: 2.4976 - val_accuracy: 0.0178\n",
      "Epoch 529/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0026 - accuracy: 0.2081 - val_loss: 2.4972 - val_accuracy: 0.0188\n",
      "Epoch 530/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.4992 - val_accuracy: 0.0182\n",
      "Epoch 531/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0026 - accuracy: 0.2087 - val_loss: 2.4835 - val_accuracy: 0.0182\n",
      "Epoch 532/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0025 - accuracy: 0.2086 - val_loss: 2.4907 - val_accuracy: 0.0200\n",
      "Epoch 533/600\n",
      "32/32 [==============================] - 26s 813ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.4929 - val_accuracy: 0.0182\n",
      "Epoch 534/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0010 - accuracy: 0.2087 - val_loss: 2.4901 - val_accuracy: 0.0180\n",
      "Epoch 535/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0035 - accuracy: 0.2083 - val_loss: 2.5221 - val_accuracy: 0.0178\n",
      "Epoch 536/600\n",
      "32/32 [==============================] - 26s 828ms/step - loss: 0.0039 - accuracy: 0.2081 - val_loss: 2.4996 - val_accuracy: 0.0190\n",
      "Epoch 537/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0018 - accuracy: 0.2085 - val_loss: 2.4932 - val_accuracy: 0.0200\n",
      "Epoch 538/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0013 - accuracy: 0.2084 - val_loss: 2.5017 - val_accuracy: 0.0175\n",
      "Epoch 539/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0021 - accuracy: 0.2086 - val_loss: 2.4910 - val_accuracy: 0.0203\n",
      "Epoch 540/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 9.4977e-04 - accuracy: 0.2087 - val_loss: 2.4959 - val_accuracy: 0.0185\n",
      "Epoch 541/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 9.6256e-04 - accuracy: 0.2087 - val_loss: 2.4977 - val_accuracy: 0.0203\n",
      "Epoch 542/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0013 - accuracy: 0.2087 - val_loss: 2.5120 - val_accuracy: 0.0195\n",
      "Epoch 543/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0014 - accuracy: 0.2087 - val_loss: 2.5115 - val_accuracy: 0.0185\n",
      "Epoch 544/600\n",
      "32/32 [==============================] - 26s 821ms/step - loss: 0.0012 - accuracy: 0.2086 - val_loss: 2.5062 - val_accuracy: 0.0190\n",
      "Epoch 545/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0015 - accuracy: 0.2087 - val_loss: 2.4935 - val_accuracy: 0.0200\n",
      "Epoch 546/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 9.8187e-04 - accuracy: 0.2086 - val_loss: 2.5179 - val_accuracy: 0.0180\n",
      "Epoch 547/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0012 - accuracy: 0.2086 - val_loss: 2.5152 - val_accuracy: 0.0192\n",
      "Epoch 548/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0016 - accuracy: 0.2084 - val_loss: 2.5232 - val_accuracy: 0.0175\n",
      "Epoch 549/600\n",
      "32/32 [==============================] - 26s 826ms/step - loss: 0.0038 - accuracy: 0.2083 - val_loss: 2.5232 - val_accuracy: 0.0155\n",
      "Epoch 550/600\n",
      "32/32 [==============================] - 26s 811ms/step - loss: 0.0012 - accuracy: 0.2086 - val_loss: 2.5168 - val_accuracy: 0.0168\n",
      "Epoch 551/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0018 - accuracy: 0.2086 - val_loss: 2.5059 - val_accuracy: 0.0178\n",
      "Epoch 552/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0023 - accuracy: 0.2084 - val_loss: 2.5238 - val_accuracy: 0.0160\n",
      "Epoch 553/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0035 - accuracy: 0.2084 - val_loss: 2.4992 - val_accuracy: 0.0182\n",
      "Epoch 554/600\n",
      "32/32 [==============================] - 29s 892ms/step - loss: 0.0024 - accuracy: 0.2086 - val_loss: 2.4938 - val_accuracy: 0.0165\n",
      "Epoch 555/600\n",
      "32/32 [==============================] - 33s 1s/step - loss: 0.0019 - accuracy: 0.2085 - val_loss: 2.4942 - val_accuracy: 0.0185\n",
      "Epoch 556/600\n",
      "32/32 [==============================] - 36s 1s/step - loss: 0.0020 - accuracy: 0.2083 - val_loss: 2.4929 - val_accuracy: 0.0172\n",
      "Epoch 557/600\n",
      "32/32 [==============================] - 28s 874ms/step - loss: 8.8609e-04 - accuracy: 0.2087 - val_loss: 2.4956 - val_accuracy: 0.0175\n",
      "Epoch 558/600\n",
      "32/32 [==============================] - 27s 839ms/step - loss: 0.0011 - accuracy: 0.2085 - val_loss: 2.4985 - val_accuracy: 0.0188\n",
      "Epoch 559/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0012 - accuracy: 0.2086 - val_loss: 2.4762 - val_accuracy: 0.0182\n",
      "Epoch 560/600\n",
      "32/32 [==============================] - 32s 990ms/step - loss: 0.0016 - accuracy: 0.2085 - val_loss: 2.5013 - val_accuracy: 0.0195\n",
      "Epoch 561/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 31s 971ms/step - loss: 0.0014 - accuracy: 0.2086 - val_loss: 2.5002 - val_accuracy: 0.0180\n",
      "Epoch 562/600\n",
      "32/32 [==============================] - 31s 979ms/step - loss: 9.0136e-04 - accuracy: 0.2087 - val_loss: 2.5134 - val_accuracy: 0.0195\n",
      "Epoch 563/600\n",
      "32/32 [==============================] - 29s 919ms/step - loss: 9.6024e-04 - accuracy: 0.2087 - val_loss: 2.5067 - val_accuracy: 0.0180\n",
      "Epoch 564/600\n",
      "32/32 [==============================] - 31s 963ms/step - loss: 0.0019 - accuracy: 0.2084 - val_loss: 2.5014 - val_accuracy: 0.0200\n",
      "Epoch 565/600\n",
      "32/32 [==============================] - 29s 906ms/step - loss: 0.0028 - accuracy: 0.2084 - val_loss: 2.4978 - val_accuracy: 0.0188\n",
      "Epoch 566/600\n",
      "32/32 [==============================] - 27s 838ms/step - loss: 0.0041 - accuracy: 0.2081 - val_loss: 2.5050 - val_accuracy: 0.0175\n",
      "Epoch 567/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0041 - accuracy: 0.2082 - val_loss: 2.5004 - val_accuracy: 0.0178\n",
      "Epoch 568/600\n",
      "32/32 [==============================] - 27s 844ms/step - loss: 0.0035 - accuracy: 0.2080 - val_loss: 2.4828 - val_accuracy: 0.0180\n",
      "Epoch 569/600\n",
      "32/32 [==============================] - 27s 832ms/step - loss: 0.0021 - accuracy: 0.2083 - val_loss: 2.4801 - val_accuracy: 0.0182\n",
      "Epoch 570/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0027 - accuracy: 0.2083 - val_loss: 2.4722 - val_accuracy: 0.0162\n",
      "Epoch 571/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0017 - accuracy: 0.2085 - val_loss: 2.4768 - val_accuracy: 0.0180\n",
      "Epoch 572/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0014 - accuracy: 0.2085 - val_loss: 2.4699 - val_accuracy: 0.0170\n",
      "Epoch 573/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0034 - accuracy: 0.2083 - val_loss: 2.4757 - val_accuracy: 0.0180\n",
      "Epoch 574/600\n",
      "32/32 [==============================] - 26s 803ms/step - loss: 0.0035 - accuracy: 0.2082 - val_loss: 2.4780 - val_accuracy: 0.0168\n",
      "Epoch 575/600\n",
      "32/32 [==============================] - 26s 817ms/step - loss: 0.0032 - accuracy: 0.2083 - val_loss: 2.4618 - val_accuracy: 0.0185\n",
      "Epoch 576/600\n",
      "32/32 [==============================] - 27s 829ms/step - loss: 0.0029 - accuracy: 0.2083 - val_loss: 2.4640 - val_accuracy: 0.0192\n",
      "Epoch 577/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0048 - accuracy: 0.2079 - val_loss: 2.4552 - val_accuracy: 0.0185\n",
      "Epoch 578/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0035 - accuracy: 0.2081 - val_loss: 2.4504 - val_accuracy: 0.0168\n",
      "Epoch 579/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0023 - accuracy: 0.2085 - val_loss: 2.4511 - val_accuracy: 0.0172\n",
      "Epoch 580/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0017 - accuracy: 0.2086 - val_loss: 2.4283 - val_accuracy: 0.0172\n",
      "Epoch 581/600\n",
      "32/32 [==============================] - 27s 833ms/step - loss: 0.0025 - accuracy: 0.2084 - val_loss: 2.4515 - val_accuracy: 0.0162\n",
      "Epoch 582/600\n",
      "32/32 [==============================] - 26s 820ms/step - loss: 0.0016 - accuracy: 0.2087 - val_loss: 2.4545 - val_accuracy: 0.0165\n",
      "Epoch 583/600\n",
      "32/32 [==============================] - 26s 816ms/step - loss: 0.0036 - accuracy: 0.2079 - val_loss: 2.4566 - val_accuracy: 0.0162\n",
      "Epoch 584/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0023 - accuracy: 0.2084 - val_loss: 2.4525 - val_accuracy: 0.0170\n",
      "Epoch 585/600\n",
      "32/32 [==============================] - 26s 823ms/step - loss: 0.0019 - accuracy: 0.2084 - val_loss: 2.4504 - val_accuracy: 0.0162\n",
      "Epoch 586/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 0.0016 - accuracy: 0.2086 - val_loss: 2.4383 - val_accuracy: 0.0170\n",
      "Epoch 587/600\n",
      "32/32 [==============================] - 26s 808ms/step - loss: 0.0011 - accuracy: 0.2086 - val_loss: 2.4491 - val_accuracy: 0.0170\n",
      "Epoch 588/600\n",
      "32/32 [==============================] - 26s 810ms/step - loss: 0.0011 - accuracy: 0.2086 - val_loss: 2.4638 - val_accuracy: 0.0155\n",
      "Epoch 589/600\n",
      "32/32 [==============================] - 26s 818ms/step - loss: 0.0032 - accuracy: 0.2083 - val_loss: 2.4706 - val_accuracy: 0.0155\n",
      "Epoch 590/600\n",
      "32/32 [==============================] - 26s 825ms/step - loss: 9.7776e-04 - accuracy: 0.2087 - val_loss: 2.4614 - val_accuracy: 0.0170\n",
      "Epoch 591/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 0.0016 - accuracy: 0.2084 - val_loss: 2.4607 - val_accuracy: 0.0168\n",
      "Epoch 592/600\n",
      "32/32 [==============================] - 26s 822ms/step - loss: 0.0011 - accuracy: 0.2087 - val_loss: 2.4858 - val_accuracy: 0.0172\n",
      "Epoch 593/600\n",
      "32/32 [==============================] - 26s 807ms/step - loss: 0.0010 - accuracy: 0.2087 - val_loss: 2.4714 - val_accuracy: 0.0175\n",
      "Epoch 594/600\n",
      "32/32 [==============================] - 26s 814ms/step - loss: 9.1377e-04 - accuracy: 0.2087 - val_loss: 2.4809 - val_accuracy: 0.0175\n",
      "Epoch 595/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0011 - accuracy: 0.2087 - val_loss: 2.4822 - val_accuracy: 0.0188\n",
      "Epoch 596/600\n",
      "32/32 [==============================] - 26s 815ms/step - loss: 0.0011 - accuracy: 0.2086 - val_loss: 2.4804 - val_accuracy: 0.0175\n",
      "Epoch 597/600\n",
      "32/32 [==============================] - 27s 828ms/step - loss: 0.0010 - accuracy: 0.2086 - val_loss: 2.4763 - val_accuracy: 0.0162\n",
      "Epoch 598/600\n",
      "32/32 [==============================] - 26s 812ms/step - loss: 0.0023 - accuracy: 0.2084 - val_loss: 2.4749 - val_accuracy: 0.0172\n",
      "Epoch 599/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 9.5389e-04 - accuracy: 0.2087 - val_loss: 2.4966 - val_accuracy: 0.0180\n",
      "Epoch 600/600\n",
      "32/32 [==============================] - 26s 809ms/step - loss: 0.0030 - accuracy: 0.2083 - val_loss: 2.4811 - val_accuracy: 0.0185\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "#Dimensionality\n",
    "dimensionality = 256\n",
    "#The batch size and number of epochs\n",
    "batch_size = 10\n",
    "epochs = 600\n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "#Model\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "#Compiling\n",
    "training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
    "#Training\n",
    "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)\n",
    "training_model.save('training_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ST5NJzSwJlDB"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "training_model = load_model('training_model.h5')\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "\n",
    "def decode_response(test_input):\n",
    "    #Getting the output states to pass into the decoder\n",
    "    states_value = encoder_model.predict(test_input)\n",
    "    #Generating empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    #Setting the first token of target sequence with the start token\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "    \n",
    "    #A variable to store our response word by word\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        #Predicting output tokens with probabilities and states\n",
    "        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
    "#Choosing the one with highest probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "#Stop if hit max length or found the stop token\n",
    "        if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "#Update the target sequence\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        #Update states\n",
    "        states_value = [hidden_state, cell_state]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "0JTKCjKVJ92i",
    "outputId": "f913afe7-5cc9-4fc5-f631-03ff762719be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "yes\n",
      " let me know when you have it working \n",
      "I have it working\n",
      " let me think do you know ifttt maybe you can do something\n",
      "Yup I can do something\n",
      " hi there how are you today \n",
      "Doing great, how about you\n",
      " yes are good friends i like that \n",
      "who's good friends?\n",
      " i m fine and you \n",
      "good\n"
     ]
    }
   ],
   "source": [
    "class ChatBot:\n",
    "  negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "#Method to start the conversation\n",
    "  def start_chat(self):\n",
    "    user_response = input(\"Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\\n\")\n",
    "    \n",
    "    if user_response in self.negative_responses:\n",
    "      print(\"Ok, have a great day!\")\n",
    "      return\n",
    "    self.chat(user_response)\n",
    "#Method to handle the conversation\n",
    "  def chat(self, reply):\n",
    "    while not self.make_exit(reply):\n",
    "      reply = input(self.generate_response(reply)+\"\\n\")\n",
    "    \n",
    "  #Method to convert user input into a matrix\n",
    "  def string_to_matrix(self, user_input):\n",
    "    tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "    user_input_matrix = np.zeros(\n",
    "      (1, max_encoder_seq_length, num_encoder_tokens),\n",
    "      dtype='float32')\n",
    "    for timestep, token in enumerate(tokens):\n",
    "      if token in input_features_dict:\n",
    "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "    return user_input_matrix\n",
    "  \n",
    "  #Method that will create a response using seq2seq model we built\n",
    "  def generate_response(self, user_input):\n",
    "    input_matrix = self.string_to_matrix(user_input)\n",
    "    chatbot_response = decode_response(input_matrix)\n",
    "    #Remove <START> and <END> tokens from chatbot_response\n",
    "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
    "    return chatbot_response\n",
    "#Method to check for exit commands\n",
    "  def make_exit(self, reply):\n",
    "    for exit_command in self.exit_commands:\n",
    "      if exit_command in reply:\n",
    "        print(\"Ok, have a great day!\")\n",
    "        return True\n",
    "    return False\n",
    "  \n",
    "chatbot = ChatBot()\n",
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "colab_type": "code",
    "id": "C7J5OMxJKEDK",
    "outputId": "008db9fd-b885-4bd6-ebb0-d86cd01d8825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm a chatbot trained on random dialogs. Would you like to chat with me?\n",
      "hi there\n",
      " hi there how are you today \n",
      "i m fine\n",
      " everything is fine on this side \n",
      "nice\n",
      " how is work going today \n",
      "all is good\n",
      " i m trying to learn like with the ukulele \n",
      "okay bye\n",
      "Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "chatbot.start_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JN9jd7lQqtbq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
